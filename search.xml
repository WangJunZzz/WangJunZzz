<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[K8S-Pod]]></title>
    <url>%2F2020%2F02%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2FK8S%2FPod%2F</url>
    <content type="text"><![CDATA[什么是Pod Pod是K8S最小调度单位。 Pod可以由一个或者多个容器组合而成。 Pod容器共享Volume 很少会直接创建一个Pod,在大多数情况下，会通过RC,RS,Deployment,DaemonSet,Job等控制器完成对一组Pod副本的创建，调度以及生命周期的自动控制任务。 通过Deployment部署一个nginx 新建并且编辑nignx-deployment.yaml 12345678910111213141516171819apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 创建Deployment 12345678910kubectl create -f nignx-deployment.yaml# 执行一下命令可以查看结果kubectl get deploymentskubectl get rskubectl get pod -o wide# [root@k8s-master k8s-yaml]# kubectl get pods# NAME READY STATUS RESTARTS AGE# nginx-deployment-59c9f8dff-kbdg6 1/1 Running 0 47s# nginx-deployment-59c9f8dff-lwnj2 1/1 Running 0 47s# nginx-deployment-59c9f8dff-whjt8 1/1 Running 0 47s 创建Service12345678910apiVersion: v1kind: Servicemetadata: name: nginxspec: ports: - port: 8888 targetPort: 80 selector: app:nginx NodePort类型：在node上打开一个端口，将该端口得流量导入到kube-proxy，然后kube-proxy进一步到对应得pod 1234567891011apiVersion: v1kind: Servicemetadata: name: nodeportservicespec: type: NodePort selector: app: nginx ports: - port: 8889 targetPort: 80 ConfigMap 生产为容器内的环境变量 设置容器启动命令的启动参数 以Volume的形式挂载为容器内部的文件或者目录 创建 通过YAML配置文件方式创建 12345678# configmap.yamlapiVersion: v1kind: ConfigMapmetadata: name: cm-vardata: level: info env: development 123456[root@k8s-master k8s-yaml]# kubectl create -f configmap.yaml configmap/cm-var created[root@k8s-master k8s-yaml]# kubectl get cmNAME DATA AGEcm-var 2 20skubectl describe configmap Pod中使用ConfigMap123456789101112131415161718192021# pod-configmap.yamlapiVersion: v1kind: Podmetadata: name: cm-test-podspec: containers: - name: cn-test image: busybox command: ["/bin/sh", "-c", "env | grep | APP"] env: - name: APPLOGLEVEL # 定义环境变量的名称 valueFrom: configMapKeyRef: name: cm-var # 环境变量的值取自以上configmap.yaml定义的cm-var key: level # key值为level - name: APPENV valueFrom: configMapKeyRef: name: cm-var key: env k8s在1.6的版本开始，引入了一个新的字段envFrom 12345678910111213# pod-envFrom-configmap.yamlapiVersion: v1kind: Podmetadata: name: cm-test-podspec: containers: - name: cn-test image: busybox command: ["/bin/sh", "-c", "env"] envFrom: - configMapRef: name: cm-var 限制条件 ConfigMap必须在Pod之前创建 Config受NameSpace的限制，必须同一个NameSpace下 支持被Api Server管理的Pod才能使用【比如静态pod无法使用】 容器内获取Pod的信息12345678910111213141516171819# pod-dapi.yamlapiVersion: v1kind: Podmetadata: name: cm-test-podspec: containers: - name: cn-test image: busybox command: ["/bin/sh", "-c", "env"] env: - name: podName # 定义环境变量的名称 valueFrom: fieldRef: podName: metadata.name - name: podId valueFrom: fieldRef: podId: status.podIP Pod升级和回滚 Deployment的升级 Nignx由1.7.9升级到1.9.1 12345678910111213141516171819202122232425# deployment-nginx.yamlapiVersion: v1kind: Deplopmentmetadata: name: deployment-nginxspec: selector: matchLabels: app: nginx replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containersPort: 80# 创建# kubeclt create -f deployment-nginx.yaml# 升级# kebectl set image deplopment/deplopment-nginx nginx=nginx:1.9.1 Deplopment的回滚 1234# 查看回滚命令kubect rollout history deplopment/deployment-nginx# 回滚到上一版本kubectl rollout undo deployment/deployment-nginx Pod的扩容 手动扩容 通过执行kubectl scale命令或者通过restful api对一个deployment/rc/rs进行pod的副本数量的设置。 以上面deployment-nginx.yaml为例[yaml中设置启动3个]12kubectl scale deplopment deployment-nginx --replicase = 5# 如果设置的replicase 小于初始化的，会“杀掉”一些运行中的Pod. 自动扩容 需要用户根据某个性能指标或者自定义业务指标，并且指定pod的副本数量范围，系统将在这个范围内根据性能指标的变化进行调整。 HPA的资源对象处于api的“autoscaling”中，目前有v1和v2两个版本，v1只支持基于CPU使用率的自动扩缩容。v2版本则支持基于任意指标的扩容配置，包括基于资源使用率，pod指标 v1版本需要预先安装Heapster组件或者Metrics Server 用于采集pod的CPU使用率 123456789101112apiVserion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: v1-auto-nginxspec: scaleTargetRef: # 目标作用对象，可以是deplopment,rs,rc apiVsersion: apps/v1 kind: Deplopment name: deplopment-nginx minReplicas: 1 maxReplicas: 10 targetCPUUtilizationPercentage: 50 # 期望每个pod的cpu使用率都是50% v2版本 123456789101112131415161718apiVersion: autoscaling/v2beta2kind: HorizontalPodAutoscalermetadata: name: v2-auto-nginxspec: scaleTargetRef: apiVersion: apps/v1 kind: deployment name: deplopment-nginx minReplicas: 1 maxReplicas: 10 metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 50]]></content>
      <tags>
        <tag>k8S</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8S安装]]></title>
    <url>%2F2020%2F02%2F09%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2FK8S%2FK8S%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[什么是K8S kubenetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台。 Master节点上运行着集群管理相关的一组进程：Kube-apiserver,Kube-controller-manager和 Kube-scheduler,这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和存储等管理功能。 Node节点上运行着kubelet，kube-proxy服务进程，这些进程负责Pod的创建、启动、监控、重启、销毁、以及实现软件模式的负载均衡器。 为什么使用K8S 新技术的驱动 Docker容器化技术已经被很多公司采用，从单机走向集群已成必然，云计算的发展正在加速这一进程 全面拥抱微服务（微服务架构使得每个服务都可以独立开发，升级和扩展，因此系统具备很高的稳定性和快速迭代能力，开发者也可以自由选择开发技术。） K8S提供的服务弹性扩容机制面对突发流量 概念和术语 Master是集群管理的控制节点，基本上所有的命令都发给它，它负责具体的执行过程。 Node是K8s中的工作负载节点，每个node都会被master分配一些工作负载。 Pod是K8s最小运行单元。 Replication Controller (RC)副本控制，声明Pod的副本数量在任意时刻都符合某个预期值。 Deployment 在内部使用Replica Set（Replocation Controller的升级）实现部署。 Horizontal Pod Autoscaler(HPA) Pod横向自动扩容；指标：CUP,QPS,TPS。 StatefulSet 有状态服务。 Service 就是我们经常提起的微服务架构中的一个一个微服务。 安装K8S [kubeadm方式] 主机 类型 操作系统 192.168.124.180 Master Centos 7 192.168.124.181 Node Centos 7 192.168.124.182 Node Centos 7 设置主机名12345678hostnamectl set-hostname masterhostnamectl set-hostname node1hostnamectl set-hostname node2# 修改 /etc/hosts192.168.124.180 master192.168.124.181 node1192.168.124.182 node2 关闭防火墙|禁用SELinux|关闭交换分区123456789# 禁用主机SELinux，让容器可以读取主机文件系统setenforce 0# 关闭防火墙systemctl disable firewalldsystemctl stop firewalld# #实时动态关闭交换分区swapoff -a #禁止重启后自动开启sed -i '/ swap / s/^/#/' /etc/fstab Yum 国内源12345cd /etc/yum.repos.d &amp;&amp; \sudo mv CentOS-Base.repo CentOS-Base.repo.bak &amp;&amp; \sudo wget -O CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo &amp;&amp; \yum clean all &amp;&amp; \yum makecache 配置k8s资源的下载地址123456789101112cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 安装Docker并且替换Docker源Docker 安装 12345678910# 换源mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123;"registry-mirrors": ["https://registry.docker-cn.com"],"exec-opts": ["native.cgroupdriver=systemd"]&#125;EOFservice docker restart 安装K8S1yum install kubelet kubeadm kubectl 下载k8s依赖镜像获取依赖的镜像1kubeadm config images list 阿里云镜像下载k8s依赖组件12345kubeadm config images list |sed -e 's/^/docker pull /g' -e 's#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/google_containers#g' |sh -xdocker images |grep registry.cn-hangzhou.aliyuncs.com/google_containers |awk '&#123;print "docker tag ",$1":"$2,$1":"$2&#125;' |sed -e 's#registry.cn-hangzhou.aliyuncs.com/google_containers#k8s.gcr.io#2' |sh -xdocker images |grep registry.cn-hangzhou.aliyuncs.com/google_containers |awk '&#123;print "docker rmi ", $1":"$2&#125;' |sh -x 开机启动12systemctl enable docker &amp;&amp; systemctl start dockersystemctl enable kubelet &amp;&amp; systemctl start kubelet 使用kubeadm安装Master12kubeadm config print init-defaults &gt; init.default.yamlkubeadm init --config=init.default.yaml 修改init.default.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: # 修改为master的ip地址 advertiseAddress: 192.168.124.180 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s-master taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: k8s.gcr.iokind: ClusterConfiguration# 修改版本为v1.17.2kubernetesVersion: v1.17.2networking: dnsDomain: cluster.local # 添加pod网段 podSubnet: "10.224.0.0/16" serviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;### 使用ipvs### yum install ipvsadm ### 查看 ipvsadm -Ln---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs # 安装成功之后执行以下命令1234567891011121314To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 192.168.124.180:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:58056cdd9dfd9cc91da880adc63a2a7e9e7594eeda1bf7c2bcdceb0fbbf255ad 安装网络插件flannel1234# 查看node还是处于NoReay状态kubectl get node# NAME STATUS ROLES AGE VERSION# k8s-master NotReady master 5h41m v1.17.2 1234# https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml kubectl create -f kube-flannel.yml# NAME STATUS ROLES AGE VERSION# k8s-master Ready master 5h59m v1.17.2 集群 node1和node2加入节点执行 12kubeadm join 192.168.124.183:6443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:58056cdd9dfd9cc91da880adc63a2a7e9e7594eeda1bf7c2bcdceb0fbbf255ad 检测集群是否安装完成 12kubectl get nodekubectl get pods --all-namespaces 问题虚拟机配置比较低，所以会出现一些错误，我们可以按照提示忽略【非生产环境】 [ERROR NumCPU CPU] 必须超过2个，把虚拟机的处理器设置一下即可。[ERROR FileContent–proc-sys-net-bridge-bridge-nf-call-iptables] 解决：echo “1” &gt; /proc/sys/net/bridge/bridge-nf-call-iptables[ERROR DirAvailable–var-lib-etcd]: /var/lib/etcd is not empty 解决：清空/var/lib/etcd 目录 https://blog.csdn.net/wangxinxinsj/article/details/90768030 https://blog.csdn.net/wangmiaoyan/article/details/101216496]]></content>
      <tags>
        <tag>k8S</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode快捷键]]></title>
    <url>%2F2020%2F01%2F12%2FVSCode%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[删除一行代码：Ctrl+shift+k 从当前光标开始新的一行 Ctrl+Enter 移动当前行 Alt+上下左右 粘贴当前行 Alt+Shift+上下 格式化代码 Alt+Shift+F “Cmd + D” 这个命令的作用是，第一次按下时，它会选中光标附近的单词；第二次按下时，它会找到这个单词第二次出现的位置，创建一个新的光标，并且选中它。这样只需要按下三次，你就选中了所有的“5”。这个时候你再按下 “右方向键”，输入“px”，即可完成任务。 Alt + Shift + i），这样操作的结果是：每一行的最后都会创建一个新的光标。 Ctrl + P 筛选到需要跳转的文件 Ctrl + Tab 文件跳转 Ctrl + g 跳转到某一行 拖拽文本 选中文字按住Ctrl]]></content>
  </entry>
  <entry>
    <title><![CDATA[IdentityServer4源码阅读]]></title>
    <url>%2F2019%2F12%2F26%2FIdentityServer4%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[https://id4withclients.readthedocs.io/en/latest/id4/ID4Database/DatabaseDiagramID4.html#client-app-related-tables]]></content>
  </entry>
  <entry>
    <title><![CDATA[开放平台搭建]]></title>
    <url>%2F2019%2F12%2F25%2F%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mysql主从搭建]]></title>
    <url>%2F2019%2F12%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMysql%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[安装mysql:docker123456#my.cnf[mysqld]datadir=/var/lib/mysql!includedir /etc/mysql/conf.d#docker rundocker run -itd --name m2s1 --privileged=true -p 3307:3306 -v /usr/local/mysql/my.cnf:/etc/mysql/my.cnf -v /usr/local/logs:/logs -v /usr/local/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD='Wangjun1234.' mysql:5.7 安装mysql:centos71234567891011121314151617181920# 下载并安装MySQL官方的 Yum Repositorywget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmyum -y install mysql57-community-release-el7-10.noarch.rpm# 安装MySQL服务器yum -y install mysql-community-server# 启动mysqlservice mysqld.service start# 查看mysql状态service mysqld.service status# 修改密码mysql -uroot -p ac!-o-:(a6+MALTER USER 'root'@'localhost' IDENTIFIED BY 'Wangjun1234.';# 开启mysql的远程访问grant all privileges on *.* to 'root'@'%' identified by 'Wangjun1234.' with grant option;flush privileges;# 关闭防火墙systemctl stop firewalld.service # 禁止firewall开机启动 systemctl disable firewalld.service mysql安装 mysql主从搭建修改主机配置文件12345678# M1主机配置# /etc/my.cnf[mysqld]#mysql主从配置 master#服务器标识server-id=1# 日志文件log-bin=master.bin 修改从机配置文件123456# M1S1从机配置# /etc/my.cnf[mysqld]#mysql主从配置 slave#服务器标识server-id=2 #### 123456789101112131415161718192021222324252627282930313233343536373839404142# 进入主机查看log文件位置show master status;+---------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+---------------+----------+--------------+------------------+-------------------+| master.000001 | 509 | | | |+---------------+----------+--------------+------------------+-------------------+# 进入从机 change master to master_host="192.168.124.16",master_port=3306,master_user="root",master_password="Wangjun1234.",master_log_file="master.000002",master_log_pos=563;# master_host 主机地址# master_port 主机端口# master_user 主机用户名# master_password 主机用户密码# master_log 主机sql日志名称（master.000001）# master_log_pos 主机日志位置（509）# 启动主从(在从机上执行)start slave;# 查看状态show slave status \G;# 停止stop slave;mysql&gt; show slave status \G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.124.16 Master_User: root Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master.000001 Read_Master_Log_Pos: 1162 Relay_Log_File: localhost-relay-bin.000002 Relay_Log_Pos: 970 Relay_Master_Log_File: master.000001 # 2个为yes代表成功 Slave_IO_Running: Yes # 如果为connecting，表示连接不上主机，如果是no，是server-id没有配置成功 Slave_SQL_Running: Yes # 如果为no，比如删除从机得数据库，再去删除主机得数据库，事务无法提交，一直阻塞# 主从配置完成# 在主机里面执行DML语句# 在从机执行查询语句 Mysql集群搭建 12345678910# M2主机配置# /etc/my.cnf[mysqld]#mysql主从配置 master#服务器标识server-id=3# 日志文件log-bin=master.bin# 因为M2即使主机也是从机，所以要开启级联复制log_slave_updates=1 123456# M2S1从机配置# /etc/my.cnf[mysqld]#mysql主从配置 slave#服务器标识server-id=4 在配置集群的时候，所有的配置和之前的主从配置是一样的，只需要在既是主机也是从机的mysql的配置文件中添加一个log_slave_updates=1即可。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mysql进阶]]></title>
    <url>%2F2019%2F11%2F30%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMysql%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[.NetCore3.0项目脚手架]]></title>
    <url>%2F2019%2F11%2F21%2FDotNet%2FNetCore3-0%E9%A1%B9%E7%9B%AE%E8%84%9A%E6%89%8B%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[构建模板 结构 Fairhr.WebApi.nuspec 1234567891011121314&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;package xmlns="http://schemas.microsoft.com/packaging/2012/06/nuspec.xsd"&gt; &lt;metadata&gt; &lt;id&gt;Fairhr.WebApi&lt;/id&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;description&gt; .Net Core3.0 WebApi项目基础架构 &lt;/description&gt; &lt;authors&gt;Dirk.Wang&lt;/authors&gt; &lt;packageTypes&gt; &lt;packageType name="Template" /&gt; &lt;/packageTypes&gt; &lt;/metadata&gt;&lt;/package&gt; 生成Nuget文件 123456789nuget pack .\Fairhr.WebApi.nuspec -OutputDirectory .# 上传到Nuget服务器nuget push .\Fairhr.WebApi.1.0.0.nupkg kTPp8jzi5cAti7Nz/5UQb1fQV0GRr/C96qkgWWS3QMGJ56UfWsyjZOXEUVY0I6aGp8UPGmI1t+3nkBJrJBZIHA== -Source http://120.77.250.111:8021/nuget# 从Nuget服务器删除nuget delete Fairhr.WebApi 1.0.0 -Source http://120.77.250.111:8021/nuget -apikey kTPp8jzi5cAti7Nz/5UQb1fQV0GRr/C96qkgWWS3QMGJ56UfWsyjZOXEUVY0I6aGp8UPGmI1t+3nkBJrJBZIHA==# 下载模板dotnet new -i Fairhr.WebApi --nuget-source http://120.77.250.111:8021/nuget# 新建项目dotnet new Fairhr.WebApi -n MyApi WebApi模板 通过脚手架安装模板 12# 如果vs上配置了nuget源，可以不需要指定--nuget-sourcedotnet new -i Fairhr.WebApi --nuget-source http://120.77.250.111:8021/nuget 查看是否安装成功 1dotnet new -l 新建webapi项目123# -n 指定项目名称 默认项目和解决方案名称为(Fairhr.WebApi) # -o 项目输出目录，可以缺省（缺失的话项目路径为当前终端打开的路径）dotnet new Fairhr.WebApi -n 项目名称 -o 指定项目目录 项目结构 Api基于.Net Core3.0,类库基于.Net Standard2.1 结合SwaggerUI + 接口版本管理 + Apollo(配置管理中心) + 日志平台(ExceptionLess) + EF + Mysql + 阿里云网关(可选) 参考文档CSDN参考文档Microsoft]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>DotNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyCat中间件]]></title>
    <url>%2F2019%2F11%2F20%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMyCat%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Java安装Java安装 Mycat安装12345wget http://dl.mycat.io/1.6-RELEASE/Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gztar -zxvf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz -C /usr/local./mycat start stop restart 分布式系统 分布式系统是指其组件分布在网络上，组件之间通过传递消息进行通信和动作协调的系统。核心理念是：让多台服务器协同工作，完成单台服务器无法处理的任务，尤其是高并发或者大数据量的任务。 透明性 对于用户是透明的，用户不必了解其内部结构。 扩展性 通过横向扩展是集群的整体性能提升，也可以通过纵向扩展单台服务器的性能提升性能。 可靠性 不允许存在单点失效的问题。 高性能 设计的初衷 Mycat Mycat是一个彻底开源的面向企业应用开发的大数据库集群，支持事务，ACID,是可以替代Mysql的加强数据库。 适用场景 高可用性和Mysql读写分离 业务数据分级存储保障 100亿大表水平切片，集群并行计算 数据库路由 整合多种数据源 核心概念 逻辑库（schema） 业务人员只需要关注数据库，mycat可以当作一个或者多个数据库集群构建的逻辑数据库。 逻辑表 读写数据的表就是逻辑表，逻辑表可以分布在一个或者多个分片库中，也可以不分片。分片表:分片表就是把数据量很大的表切分到多个数据库实例中，所有分片组合起来构成了一张完整的表。非分片表：非分片表是相对于分片表而言的不需要进行数据切分的表。 ER表 Mycat提出了基于E-R关系的数据分片策略，子表的记录与其所关联的父表记录存放在同一个数据分片上。 全局表 在一个真实的业务场景中往往存在这大量的字典表，这些字典表变动不频繁，所以mycat通过数据冗余的方式来解决这类表的关联查询。这些冗余数据的表定义为全局表。 分片节点 数据分片之后，一个大表被分到不同的分片数据库上，每个表分片所在的数据库就是分片节点。 节点主机 分片节点所在的主机就是节点主机。 配置文件Schema.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!-- 一个schema就是一个数据库 name：数据库名称 checkSqlschema:检查sql是否正确 sqlMaxLimit:自动在sql后面添加limit=100 --&gt; &lt;schema name="car" checkSQLschema="false" sqlMaxLimit="100"&gt; &lt;!-- table：属性表 name：表的名称 dataNode:该表的数据存储在哪个节点中 rule:规则的名称，auto-sharding-long（自动分片） autoIncrement：主键是否自动增长 primaryKey：真实表的主键 --&gt; &lt;table name="sy_user" primaryKey="id" dataNode="dn1,dn2,dn3,db4" rule="mod-long" /&gt; &lt;!-- &lt;table name="customer" primaryKey="ID" dataNode="dn1,dn2" rule="sharding-by-intfile"&gt; &lt;childTable name="orders" primaryKey="ID" joinKey="customer_id" parentKey="id"&gt; &lt;childTable name="order_items" joinKey="order_id" parentKey="id" /&gt; &lt;/childTable&gt; &lt;childTable name="customer_addr" primaryKey="ID" joinKey="customer_id" parentKey="id" /&gt; &lt;/table&gt; --&gt; &lt;/schema&gt; &lt;!-- &lt;dataNode name="dn1$0-743" dataHost="localhost1" database="db$0-743" /&gt; --&gt; &lt;dataNode name="dn1" dataHost="localhost1" database="db1" /&gt; &lt;dataNode name="dn2" dataHost="localhost1" database="db2" /&gt; &lt;dataNode name="dn3" dataHost="localhost1" database="db3" /&gt; &lt;dataNode name="dn4" dataHost="localhost1" database="db4" /&gt; &lt;!--&lt;dataNode name="dn4" dataHost="sequoiadb1" database="SAMPLE" /&gt; &lt;dataNode name="jdbc_dn1" dataHost="jdbchost" database="db1" /&gt; &lt;dataNode name="jdbc_dn2" dataHost="jdbchost" database="db2" /&gt; &lt;dataNode name="jdbc_dn3" dataHost="jdbchost" database="db3" /&gt; --&gt; &lt;!-- dataHost: Mycat认为他的数据库服务器必须有： 高可用，高并发 name:唯一标识 maxCon:连接池的最大连接数 minCon：连接池的最小连接数 balance:负载均衡类型； 0：不开启读写分离机制，所有的读操作都发送到当前可用的writeHost上 1：当双主双从模式（M1 ==》S1;M2 ==》 S2，并且M1和M2互为主从时），M2,S1,S2都参与select负载均衡 2：所有的读操作随机在writeHost和readHost上分发 3：所有的读操作都随机分发到writeHost的readHost上执行 writeType:mycat1.5之后的版本不在推荐食用该值 0：所有的写操作都配置的第一个writeHost1上，第一个挂了切换到writeHost2 1：随机分发 dbDriver：数据库驱动 switchType：代替废弃的writeType -1 不自动切换 1默认值自动切换 --&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1"&gt; &lt;!-- 心跳 --&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts writeHost：写的主机 --&gt; &lt;writeHost host="hostM1" url="192.168.124.16:3306" user="root" password="Wangjun1234."&gt; &lt;!-- can have multi read hosts readHost：读的主机 --&gt; &lt;readHost host="hostS1" url="192.168.124.17:3306" user="root" password="Wangjun1234." /&gt; &lt;/writeHost&gt; &lt;writeHost host="hostM2" url="192.168.124.18:3306" user="root" password="Wangjun1234."&gt; &lt;!-- can have multi read hosts readHost：读的主机 --&gt; &lt;readHost host="hostS2" url="192.168.124.17:3307" user="root" password="Wangjun1234." /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 启动MyCat 1 db1~db4需要在M1中手动建立 12345678# 启动./mycat start# 停止./mycat stop# 重启./mycat restart# 查看是否启动成功jps]]></content>
  </entry>
  <entry>
    <title><![CDATA[Flask-API]]></title>
    <url>%2F2019%2F11%2F14%2FPython%2FFlask-API%2F</url>
    <content type="text"><![CDATA[from flask import Blueprint orders = Blueprint(‘order’, name) from .OrderController import get_order from . import orders @orders.route(“”, methods=[“get”])def get_order(): return “order” from flask import Flaskfrom user import app_usersfrom Controlles import ordersapp = Flask(name) app.register_blueprint(app_users, url_prefix=’/users’)app.register_blueprint(orders, url_prefix=’/orders’) @app.route(“/“)def hello(): return “hello flask” if name == “main“: print(app.url_map) app.run(‘localhost’, 5000) pip install flask-cors r’/*’ 是通配符，让本服务器所有的URL 都允许跨域请求from flask_cors import *app = Flask(name)CORS(app, resources=r’/*’) from flask import jsonifydata = { “code”:200, “data”:[{}], “total”:200, “msg”:”success”}return jonsify(data)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask文档]]></title>
    <url>%2F2019%2F11%2F12%2FPython%2FFlask%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[安装Flask 创建虚拟环境：py -3 -m venv venv 激活虚拟环境: . venv/bin/activate 按照Flask : pip install Flask 生成requirements.txt: pip freeze &gt; requirements.txtpip install -r requirements.txt Flask-SQLAlchemy pip install flask-sqlalchemy pip install flask-mysqldb]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XUnit单元测试]]></title>
    <url>%2F2019%2F11%2F06%2FDotNet%2FXUnit%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[单元测试的价值所在 减少低级错误 减少调试时间 描述代码行为 可维护性增强 改善设计 单元测试的目的是为了给开发人员提供快速验证他们所写代码的行为.XUnit xUnit是一个测试框架，可以针对.net/core进行测试。测试项目同时需要引用xUnit库。测试编写好后，用Test Runner来运行测试。Test Runner可以读取测试代码，并且会知道我们所使用的测试框架，然后执行，并显示结果。单元测试跑通的，不代表程序没有问题;单元测试没跑通，代码程序肯定有问题.单元测试的必要 测试一个WebApi 新建XUnit项目基于EF得数据Mock Install Microsoft.EntityFrameworkCore.InMemory Install Microsoft.EntityFrameworkCore123456789101112131415161718192021222324252627282930313233private OrderInfoContext GetOrderInfoContext()&#123; // 模拟一个内存数据库 var options = new DbContextOptionsBuilder&lt;OrderInfoContext&gt;() .UseInMemoryDatabase(Guid.NewGuid().ToString()).Options; var orderInfoContext= new OrderInfoContext(options); // 添加订单数据 orderInfoContext.OrderInfo.Add(new OrderInfo() &#123; Id = "1", Name = "xunit", Money = "9999", stauts = 1, CraeteTime = DateTime.Now, UpdateTime = DateTime.Now &#125;); orderInfoContext.SaveChanges(); return orderInfoContext;&#125; /// &lt;summary&gt;/// 测试返回值是否是预期/// &lt;/summary&gt;/// &lt;returns&gt;Task&lt;/returns&gt;[Fact]public async Task Get_OrderInfo_ReturnExceptedValue()&#123; var context = GetOrderInfoContext(); var controlloer = new OrderInfoController(context); List&lt;OrderInfo&gt; result = await controlloer.GetOrderInfo(); // 断言，是否是预期的结果 Assert.Equal("xunit", result.FirstOrDefault().Name);&#125; 运行测试 测试结果转为Html Install coverlet.msbuild1234# CollectCoverage 收集覆盖率# CoverletOutput 测试报告数据输出# CoverletOutputFormat 测试报告格式,支持这些格式json (default)/lcov/opencover/cobertura/teamcitydotnet test /p:CollectCoverage=true /p:CoverletOutput='./Result/' /p:CoverletOutputFormat=opencover 1234# 全局安装：dotnet tool install --global dotnet-reportgenerator-globaltool# 执行：reportgenerator '-reports:Result/*.xml' '-targetdir:Report' Moq Install Moq 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//Arrange（设置测试数据、变量、环境等）、Act（调用要测试的函数、代码）、Assert（验证输出是否是预期的结果）private readonly ITestOutputHelper output;private Mock&lt;IUserInfoRepository&gt; userReposetory;private UserInfoController userControllerpublic UserInfoControllerXUnitTests(ITestOutputHelper testOutput)&#123; userReposetory = new Mock&lt;IUserInfoRepository&gt;(); userController = new UserInfoController(userReposetory.Object); output = testOutput;[Fact]public async Task Test_Valide_ReturnOK()&#123; //arrange var mockUser = new UserInfo &#123; UserId = 3, Name = "wangjunzzz", Email = "1232222@qq,com", Gender = 1 &#125;; userReposetory.Setup(s =&gt; s.GetUserInfos(1)).Returns(Task.FromResult(mockUser)) //act var result = await userController.GetUserInfo(1) //aasert Assert.Equal(mockUser, result);[Fact]public async Task Test_Valide_ParameIsNull()&#123; userReposetory.Setup(s =&gt; s.GetUserInfos(1)).Returns(Task.FromResult&lt;UserInfo&gt;(null)); var result = await userController.GetUserInfo(1); output.WriteLine("测试输出."); Assert.Null(result);[Fact]public void Test_CreateUserAsync_IsSuccess()&#123; //arrang var user = new UserInfo &#123; UserId = 40, Name = "zzzwnagjun", Email = "12351515@qq,com", Gender = 1 &#125;; userReposetory.Setup(s =&gt; s.GetUserInfos(1)).Returns(Task.FromResult(user)) //act var result = userController.CreateUserAsync(user).Result; output.WriteLine(result.ToString()) //assert Assert.True(result &gt; 0);[Fact]public void Test_CreateUser_IsSuccess()&#123; //arrang var user = new UserInfo &#123; UserId = 40, Name = "zzzwnagjun", Email = "12351515@qq,com", Gender = 1 &#125;; userReposetory.Setup(s =&gt; s.GetUserInfos(1)).Returns(Task.FromResult(user)) //act var result = userController.CreateUser(user); output.WriteLine(result.ToString()) //assert Assert.True(result &gt; 0);&#125; 源码示例]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一步Docker书]]></title>
    <url>%2F2019%2F10%2F29%2F%E4%B9%A6%E7%B1%8D%2F%E7%AC%AC%E4%B8%80%E6%AD%A5Docker%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[容器 容器是直接运行在操作系统内核之上的用户空间。容器不仅仅是一个单纯的运行环境，在自己的权限范围内，容器更像是一个完整的宿主机。容器有独立的网路和存储栈，还拥有自己的资源管理能力，使得同一台宿主机中的多个容器可以友好的共存。 Docker Docker是一个能够把开发得应用程序自动部署到容器得开源引擎。Docker镜像是构建docker世界得基石，用户基于镜像来运行自己得容器。镜像是Docker生命周期中得构建或者打包阶段，而容器是启动或者执行阶段。 Docker应用场景 加速本地开发和构建流程，使其更加高效，轻量化。 高性能，超大规模得宿主机部署。 Docker 命令12345678910111213141516171819202122232425262728293031323334# 拉取镜像docker pull# 查找镜像docker search images_name# 运行一个容器docker run -it --name docker_name ubuntu /bin/bash# 启动容器docker start docker_name# 停止容器docker stop docker_name# 重启容器docker restart docker_name# 查看所有容器docker ps# 附着到容器[如果推出容器得shell，容器会停止]docker attach docker_name# 查看日志docker logs docker_name# 统计容器信息docker stats# 进入容器docker exec -it docker_name /bin/bash# 自动重启容器docker run --name docker_name --restart=always ubuntu /bin/bash# 删除容器docker rm docker_name# 删除镜像docker rmi docker_image# 查看镜像docker images# wangjunzzz仓库名，static_web镜像名，v1 标签 --no-cache 不使用缓存docker build --no-cache -t="wangjunzzz/static_web:v1" # 推送镜像docker push wangjunzzz/static_web Dockerfile构建镜像指令 FROM 指定基础镜像 1FROM ubuntu:14.04 CMD 用于指定一个容器启动时要运行得命令，有点类似RUN,只是run指令是指在镜像构建是要运行得命令。docker run 命令可以覆盖CMD指令。 1CMD ["yum","install","-y","nginx"] ENTRYPOINT 和CMD指令很相似，执行cmd指令得时候docker run命令会覆盖，但是entrypoint不会，docker run 命令行中得参数都会被当作参数传递给entrypoint指令中指定得命令。 1ENTRYPOINT ["/usr/sbin/nginx","-g","daemon off"] WORKDIR 指定容器内部工作目录，entrypoint和cmd指令在该目录下执行。 1WORKDIR /opt/webapp ENV 设置环境变量 12#docker build -t supback --build-arg env="Development" .ENV ASPNETCORE_ENVIRONMENT=$env USER 指定镜像以什么样得用户去运行，默认root 12USER userUSER uid:group VOLUME 挂载卷 1VOLUME ["/data"] ADD 将构建环境下的文件和目录复制到镜像中，并且还可以解压 1ADD /mnt/test.zip /root/test.zip COPY 将构建环境下的文件和目录复制到镜像中，只是复制 1COPY /mnt/test.zip /root/test.zip LABEL 指定元数据 123#镜像的相关信息LABEL Discription="这是基于dotnetcore的泛优镜像"LABEL version="1.0" ARG 构建时候传递参数变化 123456#定义参数 通过ARG 可以在构建镜像的时候定义参数ARG env# 设置环境变量ENV ASPNETCORE_ENVIRONMENT=$env#基于之前的Dockerfile构建泛优的系统镜像docker build -t supback --build-arg env="Development" . Docker-Compose安装123456#安装pipyum -y install epel-releaseyum -y install python-pippip install --upgrade pippip install docker-compose docker-compose version]]></content>
  </entry>
  <entry>
    <title><![CDATA[Polly+HttpClientFactory]]></title>
    <url>%2F2019%2F10%2F29%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2FPolly%2BHttpClientFactory%2F</url>
    <content type="text"><![CDATA[Polly 在.Net Core中有一个被.Net基金会认可的库Polly，它一种弹性和瞬态故障处理库，可以用来简化对服务熔断降级的处理。Polly的策略主要由“故障”和“动作”两个部分组成，“故障”可以包括异常、超时等情况，“动作”则包括Fallback（降级）、重试（Retry）、熔断（Circuit-Breaker）等。策略则用来执行业务代码，当业务代码出现了“故障”中的情况时就开始执行“动作”。主要包含以下功能： 重试(Retry) 断路器(Circuit-breaker) 超时检测(Timeout) 回退(FallBack) 策略包装(PolicyWrap) 故障定义 故障也可以说是触发条件，它使用Handle来定义，表示在什么情况下，才对其进行处理（熔断，降级，重试等）。 12345678910// 单一异常种类Policy.Handle&lt;HttpRequestException&gt;();// 带条件判断的单一异常Policy.Handle&lt;SqlException&gt;(ex =&gt; ex.Number == 10)// 多种异常Policy.Handle&lt;HttpRequestException&gt;().Or&lt;OperationCanceledException&gt;()// 多种异常Policy.Handle&lt;HttpRequestException&gt;().OrResult&lt;HttpResponseMessage&gt;(res =&gt; res.StatusCode != HttpStatusCode.OK)// 返回结果异常Policy.HandleResult&lt;HttpResponseMessage&gt;(r =&gt; r.StatusCode != HttpStatusCode.OK) 重试(Retry) 重试就是指Polly在调用失败时捕获我们指定的异常，并重新发起调用，如果重试成功，那么对于调用者来说，就像没有发生过异常一样。在网络调用中经常出现瞬时故障，那么重试机制就非常重要。 123456789101112131415161718var client = new HttpClient();Policy // 处理什么异常，比如httprequrest异常 .Handle&lt;HttpRequestException&gt;() // 或者处理response的httpstatuscode 不等于200的情况 .OrResult&lt;HttpResponseMessage&gt;(res =&gt; res.StatusCode != HttpStatusCode.OK) // 重试次数 3 .Retry(3, (ex, retryCount,content) =&gt; &#123; Console.WriteLine($"请求Api异常,进行第&#123;retryCount&#125;次重试,ErrorCode:&#123;ex.Result.StatusCode&#125;"); &#125;) // 要执行的任务 .Execute(() =&gt; &#123; HttpResponseMessage res = client.GetAsync("http://qa.xx.com/Social/policy/1").Result; return res; &#125;); 回退(FallBack) 回退也称服务降级，用来指定发生故障时的备用方案。 12345678910111213141516171819var client = new HttpClient();Policy .Handle&lt;HttpRequestException&gt;() .OrResult&lt;HttpResponseMessage&gt;(res =&gt; res.StatusCode != HttpStatusCode.OK) // 出现异常只会回退处理 .Fallback(() =&gt; &#123; HttpResponseMessage res = client.GetAsync("http://qa.xx.com/Social/policy/2").Result; Console.WriteLine("Fallback（降级）处理."); return res; &#125;) .Execute(() =&gt; &#123; HttpResponseMessage res = client.GetAsync("http://qa.xx.com/Social/policy/1").Result; return res; &#125;); 超时(Timeou)Polly支持两种超时策略： TimeoutStrategy.Pessimistic： 悲观模式当委托到达指定时间没有返回时，不继续等待委托完成，并抛超时TimeoutRejectedException异常。 TimeoutStrategy.Optimistic：乐观模式这个模式依赖于 co-operative cancellation，只是触发CancellationTokenSource.Cancel函数，需要等待委托自行终止操作。123456789101112var timeoutPolicy = Policy.TimeoutAsync(1, TimeoutStrategy.Pessimistic, (context, timespan, task) =&gt; &#123; Console.WriteLine("请求超时."); return Task.CompletedTask; &#125;);timeoutPolicy.ExecuteAsync(async () =&gt;&#123; var client = new HttpClient(); await client.GetAsync("http://localhost:5000/home/delay"); return Task.CompletedTask;&#125;); 熔断(Circuit-breaker) 如果调用某个目标服务出现过多超时、异常等情况，可以采取一定时间内熔断该服务的调用，熔断期间的请求将不再继续调用目标服务，而是直接返回，节约资源，提高服务的稳定性，熔断周期结束后如果目标服务情况好转则恢复调用。 熔断状态 打开（Open） 熔断器打开状态，此时对目标服务的调用都直接返回错误，熔断周期内不会走网络请求，当熔断周期结束时进入半开状态； 关闭（Closed） 关闭状态下正常发生网络请求，但会记录符合熔断条件的连续执行次数，如果错误数量达到设定的阈值（如果在没有达到阈值之前恢复正常，之前的累积次数将会归零），熔断状态进入到打开状态； 半开（Half-Open） 半开状态下允许定量的服务请求，如果调用都成功则认为恢复了，关闭熔断器，否则认为还没好，又回到熔断器打开状态； 注意：为了服务的稳定性，在执行需要多次 Retry（重试策略）的情况下，最好组合熔断策略，预防可能存在的风险。 123456789101112131415161718192021222324252627282930313233343536373839var client = new HttpClient();var ciruitBreaker = Policy.Handle&lt;Exception&gt;() // 熔断前允许出现3次错误,熔断时间10s,熔断时触发, 熔断恢复时触发,在熔断时间到了之后触发 .CircuitBreaker(3, TimeSpan.FromSeconds(10), (ex, breakDelay) =&gt; &#123; //熔断时触发 Console.WriteLine("断路器打开,熔断触发."); &#125;, () =&gt; &#123; //熔断恢复时触发 Console.WriteLine("熔断器关闭了."); &#125;, () =&gt; &#123; //在熔断时间到了之后触发 Console.WriteLine("熔断时间到，进入半开状态"); &#125;// 模拟多次调用，触发熔断for (int i = 1; i &lt;= 150; i++)&#123; try &#123; ciruitBreaker.Execute(() =&gt; &#123; Console.WriteLine($"第&#123;i&#125;次开始执行."); var res = client.GetAsync("http://localhost:5000/home/delay").Result; Console.WriteLine($"第&#123;i&#125;次执行：正常:" + res.StatusCode); Thread.Sleep(TimeSpan.FromSeconds(1)); return res; &#125;); &#125; catch (Exception e) &#123; Console.WriteLine($"第&#123;i&#125;次执行：异常:" + e.Message); Thread.Sleep(TimeSpan.FromSeconds(1)); &#125;&#125; 熔断高级配置 根据时间段内总请求数中的异常比例触发熔断 12345678910111213141516171819202122232425262728293031323334var client = new HttpClient();var advancedCircuitBreaker = Policy.Handle&lt;Exception&gt;() .AdvancedCircuitBreaker(0.5, TimeSpan.FromSeconds(10), 3, TimeSpan.FromSeconds(10), (ex, breakDelay) =&gt; &#123; Console.WriteLine("断路器打开,熔断触发."); &#125;, () =&gt; &#123; Console.WriteLine("熔断器关闭了."); &#125;, () =&gt; &#123; Console.WriteLine("熔断时间到，进入半开状态"); &#125;);// 模拟多次调用，触发熔断for (int i = 1; i &lt;= 150; i++)&#123; try &#123; advancedCircuitBreaker.Execute(() =&gt; &#123; Console.WriteLine($"第&#123;i&#125;次开始执行."); var res = client.GetAsync("http://localhost:5000/home/delay").Result; Console.WriteLine($"第&#123;i&#125;次执行：正常:" + res.StatusCode); Thread.Sleep(TimeSpan.FromSeconds(1)); return res; &#125;); &#125; catch (Exception e) &#123; Console.WriteLine($"第&#123;i&#125;次执行：异常:" + e.Message); Thread.Sleep(TimeSpan.FromSeconds(1)); &#125;&#125; 策略包装(PolicyWrap) 策略包提供了一种灵活的方式来封装多个弹性策略(从右往左). 12345678910111213141516171819202122232425262728293031323334353637383940414243//定义超时var timeOut = Policy.Timeout(TimeSpan.FromSeconds(10), ((context, timespan, task) =&gt; &#123; Console.WriteLine("请求超时."); &#125;));//定义重试var retry = Policy.Handle&lt;Exception&gt;() .Retry(3, ((exception, retryCount, context) =&gt; &#123; Console.WriteLine($"第&#123;retryCount&#125;次重试."); &#125;)// 定义熔断策略var circuitBreaker = Policy.Handle&lt;Exception&gt;() // 熔断前允许出现3次错误,熔断时间10s,熔断时触发, 熔断恢复时触发,在熔断时间到了之后触发 .CircuitBreaker(3, TimeSpan.FromSeconds(10), (ex, breakDelay) =&gt; &#123; //熔断时触发 Console.WriteLine("断路器打开,熔断触发."); &#125;, () =&gt; &#123; //熔断恢复时触发 Console.WriteLine("熔断器关闭了."); &#125;, () =&gt; &#123; //在熔断时间到了之后触发 Console.WriteLine("熔断时间到，进入半开状态"); &#125;);//定义回退策略var fallback = Policy.Handle&lt;Exception&gt;() .Fallback(() =&gt; &#123; Console.WriteLine("正在降级处理."); &#125;fallback.Wrap(Policy.Wrap(circuitBreaker,retry, timeOut)).Execute(() =&gt;&#123; Console.WriteLine("start.");&#125;); HttpClientFactory 提供一个中心位置，用于命名和配置逻辑 HttpClient 对象. 管理 HttpClientMessageHandlers 的生存期，避免在HttpClient 生存期时出现问题. 在 HttpClient 中委托处理程序并实现基于 Polly 的中间件以利用 Polly 的复原策略。https://docs.microsoft.com/zh-cn/aspnet/core/fundamentals/http-requests?view=aspnetcore-3.0简单使用 Install Microsoft.Extensions.Http如果有多个可以同时使用 123456789101112131415161718192021222324252627282930313233343536// StartUp-&gt;ConfigureServicesservices.AddHttpClient("local",options =&gt;&#123; options.BaseAddress = new Uri("http://localhost:5000");&#125;services.AddHttpClient("fanyou",options =&gt;&#123; options.BaseAddress = new Uri("http://qa.fanyouvip.com");&#125;);//使用[Route("client")]public class ClientController : ControllerBase&#123; private readonly IHttpClientFactory _clientFactory; public ClientController(IHttpClientFactory clientFactory) &#123; _clientFactory = clientFactory; &#125; [HttpGet("Local")] public async Task&lt;IActionResult&gt; Local() &#123; var client = _clientFactory.CreateClient("local"); var res = await client.GetAsync("/home/delay"); return Ok(res); &#125; [HttpGet("Fanyou")] public async Task&lt;IActionResult&gt; Fanyou() &#123; var client = _clientFactory.CreateClient("fanyou"); var res = await client.GetAsync("/social"); return Ok(res); &#125;&#125; 结合Polly Install Microsoft.Extensions.Http.Polly 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 第一种方式services.AddHttpClient("local", options =&gt; &#123; options.BaseAddress = new Uri("http://localhost:5000"); &#125;) .AddTransientHttpErrorPolicy(p =&gt; &#123; var handlers = p.OrResult(result =&gt; result.StatusCode != HttpStatusCode.OK) .RetryAsync(3, (ex, retryCount, context) =&gt; &#123; Console.WriteLine($"第&#123;retryCount&#125;次重试.异常:&#123;ex.Exception.Message&#125;"); &#125;); return handlers; &#125;).AddTransientHttpErrorPolicy(p =&gt; &#123; var breaker = p.CircuitBreakerAsync(3, TimeSpan.FromSeconds(10)); return breaker; &#125;);//第二种方式services.AddHttpClient("Test", options =&gt; &#123; options.BaseAddress = new Uri("http://localhost:5003"); &#125;) .AddPolicyHandler(RetryPolicy()) .AddPolicyHandler(CircuiBreakerPolicy());/// &lt;summary&gt;/// 重试策略/// &lt;/summary&gt;/// &lt;returns&gt;IAsyncPolicy&lt;HttpResponseMessage&gt;&lt;/returns&gt;private IAsyncPolicy&lt;HttpResponseMessage&gt; RetryPolicy()&#123; return HttpPolicyExtensions .HandleTransientHttpError() .OrResult(res =&gt; res.StatusCode != HttpStatusCode.OK) .WaitAndRetryAsync(3, retryCount =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryCount)));/// &lt;summary&gt;/// 熔断策略/// &lt;/summary&gt;/// &lt;returns&gt;IAsyncPolicy&lt;HttpResponseMessage&gt;&lt;/returns&gt;private IAsyncPolicy&lt;HttpResponseMessage&gt; CircuiBreakerPolicy()&#123; return HttpPolicyExtensions .HandleTransientHttpError() .CircuitBreakerAsync(5, TimeSpan.FromMinutes(1));&#125; 源码示例]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能Msql(第三版)]]></title>
    <url>%2F2019%2F10%2F24%2F%E4%B9%A6%E7%B1%8D%2F%E9%AB%98%E6%80%A7%E8%83%BDMsql-%E7%AC%AC%E4%B8%89%E7%89%88%2F</url>
    <content type="text"><![CDATA[Mysql逻辑架构 每个客户端连接都会在服务器进程种拥有一个线程,这个连接的查询只会在这个单独的线程中执行，改线程只能轮流在某个CPU核心或者CPU中运行。 事务123456START TRANSACTION;-- 超出长度UPDATE `testlimit` b SET b.`IsDelete`="4515151515154156165165161651651";UPDATE `user` a SET a.`Name`='wangjun';SELECT * FROM `user`;ROLLBACK; 原子性 一个事务必须被视为一个不可分割得最小工作单元，整个事务中得所有操作要么全部成功，要么全部失败回滚，对于一个事务来讲，不可能只执行其中得一部分操作，这就是事务得原子性。 一致性 数据库总是从一个一致性得状态转换到另外一个一致性得状态。 隔离性 通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见。 持久性 一旦事务提交，则其所做的修改就会永久保存到数据库中。 四种隔离级别Read Uncommitted(未提交读) 在Read Uncommitted级别，事务中的修改，即时没有提交，对其他事务也都是可见的。事务可以读取为提交的数据，也被称为脏读(Dirty Read) Read Committed(提交读) 大多数数据系统默认的隔离级别都是Read Committed(Mysql不是)。Read Committed满足前面提到的隔离性的简单定义：一个事务开始时，只能看见已经提交的事务所做的修改。这个级别有时候也叫不可以重复读(Nonrepeatable Read) Repeatable Read(可重复读，Mysql的默认事务隔离级别) 解决了脏读的问题，保证在同一个事务中多次读取同样的记录的结果是一致的。该级别保证了在同一个事务中多次读取同样的记录结果是一致的。但是理论上，可重复读隔离级别还是无法解决另外一个幻读的问题。所谓幻读，当某个事务在读物某个范围内的记录时，另外一个事务由在该范围内插入了新的纪录，当之前的事务再次读取该范围的记录时，会产生幻行。InnoDb和XtraDb存储引擎通过多版本并发控制解决了幻读的问题。 Serializable(可串行化) 最高级别，通过强制事务串行执行，避免了前面的幻读，简单来说，Serializable会在读取的没一行数据上加上锁，所以可能倒是大量的超时和锁争用的问题。 锁 读写锁，在处理并发读或者写时，可以通过实现一个由2中类型的锁组成的锁系统来解决问题，这2中类型的锁通常被称为共享锁和排他锁，也叫读锁和写锁。锁粒度：表锁(开销最小的锁)，行级锁(开销最大的锁)死锁是指2个或者多个事务在同一个资源上相互占用，并且请求锁定对方占用的资源，从而导致恶性循环的现象。 性能优化 讲性能定义为完成某件事情所需要的时间度量，换句花说：性能即响应时间。但是性能优化就是在一定的工作负载下降低响应时间 SQL的语言分类DQL（Data Query Language）：数据查询语言 select 相关语句 DML（Data Manipulate Language）：数据操作语言 insert 、update、delete 语句 DDL（Data Define Languge）：数据定义语言 create、drop、alter 语句 TCL（Transaction Control Language）：事务控制语言 set autocommit=0、start transaction、savepoint、commit、rollback 数据类型优化1.更小的通常更好；更小的数据类型通常更快，因为它占用更少的磁盘、内存和cpu缓存，并且处理时需要的cpu周期也更少。2.简单就好；简单的数据类型操作通常需要更少的CPU周期。3.尽量避免NULL；通常情况下最好指定列为NOT NULL,除非真的需要存储NULL值，在可为NULL的列被为索引时，每个索引需要一个额外的字节。4.时间格式无特殊要求使用Timestamp5.最好避免使用BIT 创建高性能索引 索引（在MYSQL中也叫做键），是存储引擎用于快速找到记录的一种数据结构。索引优化应该是对查询性能优化的最有效的手段了，索引能够轻易将查询性能提高几个数量级。如果没有索引，执行查询时MySQL必须从第一个记录开始扫描整个表的所有记录，直至找到符合要求的记录。 索引的类型存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-test全文索引，R-Tree索引 普通索引：即一个索引只包含单个列，一个表可以有多个单列索引唯一索引：索引列的值必须唯一，但允许有空值复合索引：即一个索引包含多个列 B-Tree]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.Net Core GRpc]]></title>
    <url>%2F2019%2F10%2F22%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2FGRpc%2F</url>
    <content type="text"><![CDATA[.Net Core GRpc gRPC 是一种与语言无关的高性能远程过程调用 (RPC) 框架。 现代高性能轻量级 RPC 框架。 协定优先 API 开发，默认使用协议缓冲区，允许与语言无关的实现。 可用于多种语言的工具，以生成强类型服务器和客户端。 支持客户端、服务器和双向流式处理调用。 使用 Protobuf 二进制序列化减少对网络的使用。 使用GRpc,请先了解Protocol buffer 语法. Protobuf3 语法-中文版 官网文档 GRpc 的数据交互方式1. Unary RPCs，一次请求，一次返回，没有流，123//这是最常用的方式：rpc SayHello(HelloRequest) returns (HelloResponse)&#123;&#125; 2. Server streaming RPCs，客户端发送单次请求，服务端会返回一连串的数据。123//比如服务端向客户端推送站内即时消息：rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125; 3. Client streaming RPCs，客户端会发送一连串的数据到服务端，服务端返回单次数据.123//比如发送实时日志：rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) &#123;&#125; 4. Bidirectional streaming RPCs，双向流，两边各自会发送一连串的数据。123//比如实时语音通话以及一些游戏场景中：rpc BidiHello(stream HelloRequest) returns (stream HelloResponse)&#123;&#125; 创建GRpc服务 Protos目录下添加 OrderGrpcServer.proto 1234567891011121314151617181920212223242526272829// 使用proto3语法，不写这个默认使用proto2语法syntax = "proto3"; // 指定C#命名空间option csharp_namespace = "GrpcService.Order";// 包名package Order;// 定义一个grpc 服务service OrderGrpcService &#123; // 定义一个新增订单的方法 rpc AddOrder (OrderRequest) returns (HelloReply);&#125;// 定义AddOrder请求参数// int32 字段类型，id 字段名称，1 字段标识号（用来在消息的二进制格式中识别各个字段的）message OrderRequest&#123; int32 id = 1; string name = 2; double price = 3; string Remark = 4;&#125;//定义AddOrder返回值message OrderResponse&#123; int32 id = 1; int32 isSuccess = 2;&#125; 修改项目的xx.csproj 1234&lt;ItemGroup&gt; //GrpcServices = server 服务端，还有对于的Client &lt;Protobuf Include="Protos\OrderGrpcServer.proto" GrpcServices="Server" /&gt;&lt;/ItemGroup&gt; 编译之后会在项目下生成2个cs文件 实现服务 创建客户端(我这里创建了一个控制台应用程序) 1234// 添加Nuget包Grpc.Net.ClientGoogle.ProtobufGrpc.Tools 把服务端的Protos赋值到客户端项目中，并且修改xx.csporj文件 调用 1234567891011121314static void Main(string[] args)&#123; var channel = GrpcChannel.ForAddress("https://localhost:5001"); var client = new OrderGrpcService.OrderGrpcServiceClient(channel); var response = client.AddOrder(new OrderRequest &#123; Id = 11, Name = "98k", Price = 556, Remark = "测试" &#125;); Console.WriteLine(response); Console.ReadKey();&#125; 示例代码]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23种设计模式]]></title>
    <url>%2F2019%2F09%2F30%2FDotNet%2F23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Source 前言面向对象设计模式通常以类或者对象的描述其中的关系和相互作用，但不涉及用来完成应用程序的特定类或者对象。设计模式能使不稳定依赖于相对稳定，具体依赖相对抽象，避免引起麻烦的紧耦合，以增强软件设计面对适应变化的能力。 六大原则 单一职责原则：如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者抑制这个类完成其他职责的能力。这种耦合会导致脆弱的设计，当变化发生时，设计会遭受到意想不到的破坏。 里氏替换原则：子类可以扩展父类的功能，但不能改变父类原有的功能，告诉我们不要破坏继承体系。 依赖倒置原则：面向接口编程。 接口隔离原则：设计接口的时候要精简单一 迪米特原则：降低类与类之间的耦合。 开闭原则：要对扩展开放，对修改关闭。 创建型单件模式(Singleton Pattern) 在软件系统中，经常有这样一些特殊的类，必须保证它们在系统中只存在一个实例，才能确保它们的逻辑正确性、以及良好的效率。保证一个类仅有一个实例，并提供一个访问它的全局访问点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 单线程实现singletonnamespace Singleton_Pattern&#123; public class SingleThreadSingleton &#123; private static SingleThreadSingleton instance = null; // 构造方法让其private,这就堵死了外界利用new创建此类实例的可能 private SingleThreadSingleton() &#123; &#125; public static SingleThreadSingleton Instance &#123; get &#123; if (instance == null) &#123; instance=new SingleThreadSingleton(); &#125; return instance; &#125; &#125; public void Print() &#123; Console.WriteLine("hello singletion!!!"); &#125; &#125;&#125;// 多线程实现singletonnamespace Singleton_Pattern&#123; public class MultiThreadSingleton &#123; private static volatile MultiThreadSingleton instance = null; private static object lockHelper = new object(); private MultiThreadSingleton() &#123; &#125; public static MultiThreadSingleton Instance &#123; get &#123; if (instance == null) &#123; lock (lockHelper) &#123; if (instance == null) &#123; instance=new MultiThreadSingleton(); &#125; &#125; &#125; return instance; &#125; &#125; public void Print() &#123; Console.WriteLine("hello singletion!!!"); &#125; &#125;&#125; 单例模式和静态方法类的区别（1）代码结构上 单例模式可以有非静态方法和成员的，而且只要获得了实例就可以去调用； 静态方法类通常来说全是静态方法，如果有非静态方法，是不能直接调用的。 （2）编程思想上 单例模式是普通的类，只不过它是有一个实例而已，符合JAVA面向对象的思想； 静态方法类通常又称为工具类，它更像是面向过程的一个函数集。 （3）特性上 单例模式符合所有面向对象的特性，可以去继承类、可以实现接口、可以被继承、方法可以被重写、可以用于多态（不 同实现）； 而静态方法类不能。 （4）生命周期上 单例模式可以延迟初始化，并且一直到运行结束才会被回收； 静态方法类在第一次使用时就会被加载，执行完静态方法后就会被回收，如果频繁调用会导致频繁地初始化和释放。 （5）实例化上 单例模式需要进行实例化（通过静态方法中的new）； 静态方法类不需要实例化，可以直接调用。 （6）内存占用上 单例模式调用哪个方法，就载入哪个方法，但是它需要长时间地维护一个对象； 静态方法类需要把所有静态方法都载入内存，不管你用不用。 （7）线程与共享 单例模式的多线程控制很方便，适合维护或者共享一些配置状态信息； 静态方法类的多线程控制则非常糟糕 工厂方法模式（Factory Method) 工厂方法模式(Factory Method Pattern)又称为工厂模式，也叫虚拟构造器(Virtual Constructor)模式或者多态工厂(Polymorphic Factory)模式，它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。 工厂方法模式包含如下角色： Product：抽象产品 ConcreteProduct：具体产品 Factory：抽象工厂 ConcreteFactory：具体工厂场景有这么一个需求：XX系统需要支持对数据库中的员工薪资进行导出，并且支持多种格式如：HTML、CSV、PDF等，每种格式导出的结构有所不同，比如：财务跟其他人对导出薪资的HTML格式要求可能会不一样，因为财务可能需要特定的格式方便核算或其他用途。如果使用简单工厂模式，则工厂类必定过于臃肿。因为简单工厂模式只有一个工厂类，它需要处理所有的创建的逻辑。假如以上需求暂时只支持3种导出的格式以及2种导出的结构，那工厂类则需要6个if else来创建6种不同的类型. 抽象工厂（ExportFactory）角色：担任这个角色的是工厂方法模式的核心，任何在模式中创建对象的工厂类必须实现这个接口。在实际的系统中，这个角色也常常使用抽象类实现。 具体工厂（ExportHtmlFactory、ExportPdfFactory）角色：担任这个角色的是实现了抽象工厂接口的具体类。具体工厂角色含有与业务密切相关的逻辑，并且受到使用者的调用以创建导出类（如：ExportStandardHtmlFile）。 抽象导出（ExportFile）角色：工厂方法模式所创建的对象的超类，也就是所有导出类的共同父类或共同拥有的接口。在实际的系统中，这个角色也常常使用抽象类实现。 具体导出（ExportStandardHtmlFile等）角色：这个角色实现了抽象导出（ExportFile）角色所声明的接口，工厂方法模式所创建的每一个对象都是某个具体导出角色的实例。 Code Soucre参考-博客园 抽象工厂（Abstract Factory）建造者模式(Builder)原型模式(Prototype)结构型适配器模式（Adapter Pattern)桥接模式（Bridge Pattern)装饰模式(Decorator Pattern)组合模式(Composite Pattern)外观模式（Facade Pattern)享元模式(Flyweight Pattern)代理模式(Proxy Pattern)行为型模板方法(Template Method)命令模式(Command Pattern)迭代器模式(Iterator Pattern)观察者模式(Observer Pattern）解释器模式(Interpreter Pattern)中介者模式(Mediator Pattern)职责链模式(Chain of Responsibility Pattern)备忘录模式(Memento Pattern)策略模式(Strategy Pattern)访问者模式(Visitor Pattern)状态模式(State Pattern)参考-Design-Pattern参考-Graphic Design Patterns]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>DotNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读微服务设计]]></title>
    <url>%2F2019%2F09%2F26%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F%E8%AF%BB%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[请输入密码以阅读这篇私密文章。 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]]></content>
  </entry>
  <entry>
    <title><![CDATA[微服务架构]]></title>
    <url>%2F2019%2F09%2F23%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[微服务架构图 配置中心背景随着业务的发展、微服务架构的升级，服务的数量、程序的配置日益增多（各种微服务、各种服务器地址、各种参数），传统的配置文件方式和数据库的方式已无法满足开发人员对配置管理的要求： 安全性：配置跟随源代码保存在代码库中，容易造成配置泄漏； 时效性：修改配置，需要重启服务才能生效； 局限性：无法支持动态调整：例如日志开关、功能开关； 因此，我们需要配置中心来统一管理配置！把业务开发者从复杂以及繁琐的配置中解脱出来，只需专注于业务代码本身，从而能够显著提升开发以及运维效率。同时将配置和发布包解藕也进一步提升发布的成功率。 简介Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。 Features统一管理不同环境、不同集群的配置 Apollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。 同一份代码部署在不同的集群，可以有不同的配置，比如zk的地址等。 通过命名空间（namespace）可以很方便的支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖。配置修改实时生效（热发布） 用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序。灰度发布 支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例。 携程Apollo再.Net FrameWork上的使用- 新建一个.Net Framework4.7.2的项目 - 添加Com.Ctrip.Framework.Apollo.ConfigurationManager包引用 - 再Web.config的appSettings目录下添加12&lt;add key="Apollo.AppId" value="framework.web" /&gt;&lt;add key="Apollo.MetaServer" value="http://192.168.19.48:8080/" /&gt; - 获取配置文件1234// ApolloConfigurationManager 不过这个是过时的IConfig config = await ApolloConfigurationManager.GetAppConfig();// 获取apollo配置好的连接字符串return config.GetProperty("ConnectionStrings", string.Empty); 携程Apollo再.NetCore2.x上的使用- 新建一个.NetCore2.2项目 - 添加Com.Ctrip.Framework.Apollo.Configuration包引用 - 配置appsettings.json1234567891011&#123; "apollo": &#123; "AppId": "fanyouvip.com" &#125;&#125;// appsettings.development.json&#123; "apollo": &#123; "MetaServer": "http://192.168.19.48:8080" &#125;&#125; - 在Program-&gt;Main函数中添加123456789public static IWebHostBuilder CreateWebHostBuilder(string[] args)&#123; return WebHost.CreateDefaultBuilder(args) .ConfigureAppConfiguration(builder =&gt; builder .AddApollo(builder.Build().GetSection("apollo")) //.AddNamespace("fanyou") // 命名空间 .AddDefault()) .UseStartup&lt;Startup&gt;();&#125; 使用方式一(注入IConfiguration)：12345678910111213141516[Route("api/[controller]")][ApiController]public class ValuesController : ControllerBase&#123; private readonly IConfiguration configuration; public ValuesController(IConfiguration config) &#123; configuration = config; &#125; // GET api/values [HttpGet] public string Get() &#123; return configuration["Test"].ToString(); &#125;&#125; 使用方式二(POCO):- 添加Tuhu.Extensions.Configuration.ValueBinder.Json包引用1234567891011121314151617181920// 在apollo中配置文件是Json格式。项目中建立对于的实体services.ConfigureJsonValue&lt;ConfigMsg&gt;(Configuration.GetSection("Test"));// 获取配置文件信息[Route("api/[controller]")][ApiController]public class ValuesController : ControllerBase&#123; private IOptions&lt;ConfigMsg&gt; config; public ValuesController(IOptions&lt;ConfigMsg&gt; configMsg) &#123; config = configMsg.Value; &#125; [HttpGet] public int Get() &#123; return config.request_timeout; &#125;&#125; Source CodeApollo GithubDevelopor Guide API网关阿里云API网关文档 阿里云API 网关为您提供完整的 API 托管服务，辅助用户将能力、服务、数据以 API 的形式开放给合作伴。 阿里云API 网关提供防攻击、防重放、请求加密、身份认证、权限管理、流量控制等多重手段保证 API 全，降低 API 开放风险。 提供 API 定义、测试、发布、下线等全生命周期管理，并生成 SDK、API 说明文档，提升 API 管理、迭代效率。 提供便捷的监控、报警、分析、API 市场等运维、运营工具，降低 API 运营、维护成本。请求签名说明文档名词解释【必选】X-Ca-Key：AppKey 【必选】X-Ca-Signature：签名字符串 【可选】X-Ca-Timestamp：API 调用者传递时间戳，值为当前时间的毫秒数，也就是从1970 年1月1日起至今的时间转换为毫秒，时间戳有效时间为15分钟 【可选】X-Ca-Nonce：API 调用者生成的 UUID，结合时间戳防重放 【可选】Content-MD5 当请求 Body 非 Form 表单时，可以计算 Body 的 MD5 值传递给云网 关进行 Body MD5 校验 【可选】X-Ca-Stage请求 API 所属 Stage，目前仅支持 TEST 、PRE 和 RELEASE，默认 RELEASE，若您调用的 API 不在线上环境，请一定要指定该参数的值，否则会报 URL 错误Vue1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# npm install aliyun-api-gateway -S# 在main.js中const Client = require(&apos;aliyun-api-gateway&apos;).Client;const client = new Client(&apos;appkey&apos;, &apos;appsecret&apos;);Vue.prototype.client = client# GETlet opts = &#123; headers: &#123; &quot;content-type&quot;: &quot;application/json; charset=UTF-8&quot;, &quot;X-Ca-Stage&quot;: this.env &#125;&#125;;this.client .get( &quot;http://api.permit.fanyouvip.com/api/Public/Role/xx/xx&quot;, opts ) .then(e =&gt; &#123; console.log(e); &#125;) .catch(err =&gt; &#123; console.log(err); console.log(err.code); &#125;);# POSTlet opts = &#123; headers: &#123; &quot;content-type&quot;: &quot;application/json; charset=UTF-8&quot;, &quot;X-Ca-Stage&quot;: this.env &#125;, data: &#123; userName: &quot;admin&quot;, password: &quot;123&quot;, systemId: &quot;e92983fd6e4c4f598b1e7dfb9d636501&quot; &#125;&#125;;this.client .post(&quot;http://api.permit.fanyouvip.com/api/Public/Login&quot;, opts) .then(res =&gt; &#123; console.log(res); &#125;) .catch(err =&gt; &#123; console.log(err); console.log(err.code); &#125;);&#125; 在Vue中有一个小问题，需要注释调HTTPX中的一段代码，请参考。 .Net Core 2.x 整理了一下阿里云官网提供的SDK文档，发布到私有的Nuget服务器上。 安装 Fairhr.ApiGetWay 在StartUp -&gt; ConfigureServices 12345678910111213141516171819services.AddFarihrGetWay(options =&gt;&#123; options.AppKey = "AppKey"; options.AppSecret = "AppSecret"; // api网关地址 options.Host = "api网关地址"; // 配置环境变量 options.Environment = "TEST&#125;);// 调用apistring result = string.Empty;using (HttpWebResponse response = HttpCoreUtil.HttpGet("/Social/Policy/repair/month/2341"))&#123; Stream st = response.GetResponseStream(); StreamReader reader = new StreamReader(st, Encoding.GetEncoding("utf-8"); result = reader.ReadToEnd();&#125; .Net Framework 整理了一下阿里云官网提供的SDK文档，发布到私有的Nuget服务器上。 安装 Fairhr.ApiGetWay 1234567string result = string.Empty;using (HttpWebResponse response = HttpFrameWorkUtil.HttpGet("api网关地址", Path, "AppKey","AppSecret"))&#123; Stream st = response.GetResponseStream(); StreamReader reader = new StreamReader(st, Encoding.GetEncoding("utf-); result = reader.ReadToEnd().ToString();&#125; 注意 Header 部分。其中 X-Ca开头的均为网关返回(在 Header 中获得 X-Ca-Error-Message 可以基本明确报错原因，而 X-Ca-Request-Id 可以用于提供给这边的支持人员，供支持人员搜索日志)。 1234567X-Ca-Request-Id: 7AD052CB-EE8B-4DFD-BBAF-EFB340E0A5AF //请求唯一ID，请求一旦进入API网关应用后，API网关就会生成请求ID并通过响应头返回给客户端.//建议客户端与后端服务都记录此请求ID，可用于问题排查与跟踪X-Ca-Error-Message: Invalid Url //API网关返回的错误消息，当请求出现错误时API网关会通过响应头将错误消息返回给客户端X-Ca-Debug-Info: &#123;"ServiceLatency":0,"TotalLatency":2&#125; //当打开Debug模式后会返回Debug信息，此信息后期可能会有变更，仅用做联调阶段参考 返回值为空。（HTTP/HTTPS 请求的返回结果有 HttpCode、Header、Body 三部分。当请求报错时，由于没有进入业务逻辑，所以返回的 Body 可能为空，表现为“返回值为空”，但实际上，重要信息都在 Header 里面。） 服务注册和服务发现新建项目 Install-Package OcelotInstall-Package Ocelot.Provider.Consul 添加Ocelot.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; "ReRoutes": [ &#123; "DownstreamPathTemplate": "/&#123;url&#125;", "DownstreamScheme": "http", "DownstreamHostAndPorts": [ &#123; "Host": "localhost", "Port": 5001 &#125; ], "UpstreamPathTemplate": "/&#123;url&#125;", "UpstreamHttpMethod": [ "Get", "Post", "Put", "Delete", "Patch" ], "AuthenticationOptions": &#123; // 添加IdentityServer4 "AuthenticationProviderKey": "ocelotKey", "AllowedScopes": [] &#125;, "ServiceName": "order", // 使用consul的时候配置，consul的服务名称 "LoadBalancerOptions": &#123; // 使用consul的时候配置 "Type": "LeastConnection" // 使用consul的时候配置，RoundRobin（轮询方式）和LeastConnection（最小连接） &#125;, // 使用consul的时候配置 "UseServiceDiscovery": true // 使用consul的时候配置，是否启用服务发现 &#125;, &#123; "DownstreamPathTemplate": "/&#123;url&#125;", "DownstreamScheme": "http", "DownstreamHostAndPorts": [ &#123; "Host": "localhost", "Port": 5002 &#125; ], "UpstreamPathTemplate": "/api/&#123;url&#125;", "UpstreamHttpMethod": [ "Get", "Post", "Put", "Delete", "Patch" ] &#125; ], "GlobalConfiguration": &#123; "BaseUrl": "http://localhost:5000", "ServiceDiscoveryProvider": &#123; //使用consul的时候配置，配置服务发现 "Host": "localhost", //使用consul的时候配置，主机地址 "Port": 8500, //使用consul的时候配置，端口 "Type": "Consul", //使用consul的时候配置 "PollingInterval": 100 //使用consul的时候配置，轮询的间隔时间，以毫秒为单位。 &#125;&#125; 修改StartUp 123456789101112131415161718192021222324252627282930313233services.AddAuthentication(IdentityServerAuthenticationDefaults.AuthenticationScheme).AddIdentityServerAuthentication("ocelotKey", options =&gt; &#123; options.Authority = "http://dev.oauth.fanyouvip.com"; options.RequireHttpsMetadata = false; options.ApiName = "apigetway"; options.SupportedTokens = SupportedTokens.Both; options.ApiSecret = "secret";&#125;);services.AddOcelot(new ConfigurationBuilder().AddJsonFile("ocelot.json").Build()).AddConsul();app.UseAuthentication().UseOcelot().Wait();#### 服务注册``` json//注册地址，[PUT] http://localhost:8500/v1/agent/service/register // Body &#123; "ID": "order001", "Name": "order", "Tags": [ "order", "v1" ], "Address": "localhost", "Port": 5001, "EnableTagOverride": false, "Check": &#123; "DeregisterCriticalServiceAfter": "12h", "HTTP": "http://localhost:5001/health", "Interval": "1s" &#125;&#125; Source CodeOcelot DocConsul Doc 服务注册应用程序设计什么是分布式事务随着微服务架构的普及，一个大型业务系统往往由若干个子系统构成，这些子系统又拥有各自独立的数据库。往往一个业务流程需要由多个子系统共同完成，而且这些操作可能需要在一个事务中完成。在微服务系统中，这些业务场景是普遍存在的。此时，我们就需要在数据库之上通过某种手段，实现支持跨数据库的事务支持，这也就是大家常说的“分布式事务”。 CAP理论 CAP理论说的是：在一个分布式系统中，最多只能满足C、A、P中的两个需求。 CAP的含义： C：Consistency 一致性 同一数据的多个副本是否实时相同。 A：Availability 可用性 可用性：一定时间内 &amp; 系统返回一个明确的结果 则称为该系统可用。 P: Partition tolerance 分区容错性 将同一服务分布在多个系统中，从而保证某一个系统宕机，仍然有其他系统提供相同的服务。 对于一个业务系统来说，可用性和分区容错性是必须要满足的两个条件，并且这两者是相辅相成的。业务系统之所以使用分布式系统，主要原因有两个： 提升整体性能 当业务量猛增，单个服务器已经无法满足我们的业务需求的时候，就需要使用分布式系统，使用多个节点提供相同的功能，从而整体上提升系统的性能，这就是使用分布式系统的第一个原因。 实现分区容错性 单一节点 或 多个节点处于相同的网络环境下，那么会存在一定的风险，万一该机房断电、该地区发生自然灾害，那么业务系统就全面瘫痪了。为了防止这一问题，采用分布式系统，将多个子系统分布在不同的地域、不同的机房中，从而保证系统高可用性。 BASE理论CAP理论告诉我们一个悲惨但不得不接受的事实——我们只能在C、A、P中选择两个条件。而对于业务系统而言，我们往往选择牺牲一致性来换取系统的可用性和分区容错性。不过这里要指出的是，所谓的“牺牲一致性”并不是完全放弃数据一致性，而是牺牲强一致性换取弱一致性。 BA：Basic Available 基本可;整个系统在某些不可抗力的情况下，仍然能够保证“可用性”，即一定时间内仍然能够返回一个明确的结果。 S：Soft State：柔性状态 同一数据的不同副本的状态，可以不需要实时一致。 E：Eventual Consisstency：最终一致性 同一数据的不同副本的状态，可以不需要实时一致，但一定要保证经过一定时间后仍然是一致的。 基于可靠消息服务的分布式事务Dotnetcore.CAP 是一个基于 .NET Standard 的 C# 库，它是一种处理分布式事务的解决方案，同样具有 EventBus 的功能，它具有轻量级、易使用、高性能等特点。 CAP架构图 DotNetCore.CAP Source CodeCAP Demo Source Code 任务调度中心Hangfire 新建项目，添加一下包 123Hangfire.HttpJobHangfire.MySqlStorageHangfire.Dashboard.BasicAuthorization 修改Startup.cs 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// ConfigureServicesservices.AddHangfire(ConfigurationHangfire);// Configure// 中文面板System.Threading.Thread.CurrentThread.CurrentUICulture = new System.Globalization.CultureInfo("zh-app.UseHangfireServer(new BackgroundJobServerOptions()&#123; // queue name参数只能由小写字母、数字、下划线和破折号（自1.7.6起）字符组成。 Queues = Configuration["queue"].Split(new char[','], StringSplitOptions.RemoveEmptyEntries)//只读面板，只能读取不能操作app.UseHangfireDashboard("/read", readOpti// 管理员面板app.UseHangfireDashboard("/jobs", adminOptions);//Hangfire配置 https://github.com/yuzd/Hangfire.HttpJob/wikiprivate DashboardOptions adminOptions = new DashboardOptions()&#123; DisplayStorageConnectionString = false, IsReadOnlyFunc = context =&gt; false, IgnoreAntiforgeryToken = true, Authorization = new[] &#123; new BasicAuthAuthorizationFilter(new BasicAuthAuthorizationFilterOptions() &#123; RequireSsl=false, SslRedirect=false, LoginCaseSensitive=true, Users=new []&#123; new BasicAuthAuthorizationUser &#123; Login="admin", PasswordClear="123" &#125;, new BasicAuthAuthorizationUser &#123; Login="fanyou", PasswordClear="123" &#125; &#125; &#125;)&#125;&#125;;private DashboardOptions readOptions = new DashboardOptions()&#123; IgnoreAntiforgeryToken = true, DisplayStorageConnectionString = false, IsReadOnlyFunc = context =&gt; true&#125;;private void ConfigurationHangfire(IGlobalConfiguration globalConfiguration)&#123; globalConfiguration.UseStorage( new MySqlStorage(Configuration["jobdb"], new MySqlStorageOptions() &#123; QueuePollInterval = TimeSpan.FromSeconds(15), JobExpirationCheckInterval = TimeSpan.FromHours(1), CountersAggregateInterval = TimeSpan.FromMinutes(5), PrepareSchemaIfNecessary = true, DashboardJobListLimit = 50000, TransactionTimeout = TimeSpan.FromMinutes(2), TablesPrefix = "Fairhr_" &#125;)) .UseConsole() .UseHangfireHttpJob(new HangfireHttpJobOptions() &#123; DashboardName = "泛亚统一任务调度平台", DashboardTitle = "调度平台", DashboardFooter = string.Empty, MailOption = new MailOption() &#123; Server = "smtp.qq.com", Port = 465, UseSsl = true, User = "510423039@qq.com", Password = "vkskogjacsqabjgd" &#125; &#125;)&#125; 在任务调度平台添加周期性任务 在任务调度平台添加延迟任务 通过接口注册定时任务和延迟任务123456789101112131415161718192021222324//Install-Package Hangfire.HttpJob.Client// 定时任务var result = HangfireJobClient.AddRecurringJob("调度平台Server地址", new RecurringJob()&#123; JobName = "测试5点40执行", Method = "Post", Data = new &#123;name = "aaa",age = 10&#125;, Url = "http://localhost:5000/api/vaules", Mail = new List&lt;string&gt; &#123; "510423039@qq.com" &#125;, SendSucMail = true, Cron = "40 17 * * *"&#125;//延迟任务var result = HangfireJobClient.AddBackgroundJob("调度平台Server地址", new BackgroundJob&#123; JobName = "测试api", Method = "Get", Url = "http://localhost:5000/api/values/11", Mail = new List&lt;string&gt; &#123;"510423039@qq.com"&#125;, SendSucMail = true, DelayFromMinutes = 1&#125; 日志中心Exceptionless Exceptionless 是一个开源的实时的日志收集框架，它可以应用在基于 ASP.NET，ASP.NET Core，Web Api，Web Forms，WPF，Console，MVC 等技术栈的应用程序中，并且提供了Rest接口可以应用在 Javascript，Node.js 中。 首先，需要去官网注册一个帐号，注册完成之后登录系统。 Install-Package Exceptionless.AspNetCore app.UseExceptionless(“key”); 容器服务部署]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Restful-Web-API]]></title>
    <url>%2F2019%2F08%2F31%2FCICD%2FRestful-Web-API%2F</url>
    <content type="text"><![CDATA[Rest不是一个协议，也不是一种文件格式，更不是一种开发框架。它是一系列的涉及约束的集合：无状态性，讲超媒体作为应用状态的引擎等。 服务器发送的表述用于描述资源当前的状态，客户端发送的表述用于描述客户端希望资源拥有的状态，这就是表述性状态转移。 GET 获取资源的某个表述，请求成功返回200 POST 基于给定的表述信息，在当前资源的下一级创建新的资源，（201，创建成功，202表示服务器按照提供的表述信息来创建一个资源，但是现在还没有真正的创建完成），不安全也不幂等。 DELETE 销毁一个资源，（如果一个delete请求成功，服务器可能返回204表示已经删除成功了，或者是200，也有可能是202意识是讲在稍后删除这个资源），如果试图通过get访问一个被删除的资源，应该是404或者410. PUT 用给定的表述信息替换资源的当前状态，（返回200或者204）用于修改资源状态的请求，发送10次put请求和1次结果都是一样的，所以是幂等的。 幂等性：发送多次请求对资源的状态的影响和发送一次的请求的影响是一样的。（get和delete和put是幂等性安全的方法），幂等的概念来源于数学，零乘运算就是幂等运算，讲一个值乘以0等到的都是同样的结果。]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Https]]></title>
    <url>%2F2019%2F08%2F27%2FCICD%2FHttps%2F</url>
    <content type="text"><![CDATA[Http的定义 http提供了一组规则和标准，从而让信息能够在互联网上进行传播。 http 超文本传输协议；tcp 传输控制协议 ；ip 网间协议； 通过ip地址+协议+端口标识网络中的一个进程，标识唯一一个进程之后，就可以进行socket通信了，socket是应用层和传输层之间的一个抽象层，它把tcp/ip层复杂的操作抽象为几个简单的接口提供给应用层调用，实现网络中的通信。 socket是对tcp/ip的封装，socket本事并不是协议，而是一个调用接口，通过socket，我们才能使用tcp/ip协议。 TCP/IP 五层模型 应用层：负责应用程序之间的沟通。网络编程主要针对的就是应用层,（http,ftp,邮件协议[SMTP、POP3、IMAP4]） 传输层：负责两台主机之间的数据传输,(tcp) 网络层：负责地址管理和路由选择。路由器工作在网络层,(ip) 数据链路层：负责设备之间的数据帧的传输和识别。交换机工作在数据链路层。例如网卡设备的驱动，帧同步，冲突检测，数据差错校验等工作,(以太网协议) 物理层：负责光电信号传递方式。集线器工作在物理层。以太网协议 http是无状态 http是基于tcp/ip协议，当一个tcp连接关闭之后，所有的http请求和响应信息全部消失，在http中，客户端通过socket技术创建一个tcp/ip连接，并且连接到服务器，完成信息交换后，就会关闭tcp连接。所谓的无状态就是每次完成请求后,不会在客户端和服务端保存任何信息，对于客户端和服务端来说，根本不知道上次的请求信息是什么，它的生命周期随着tcp/ip的关闭结束了。 http本事是不能传输的，需要通过网络层中的其他协议进行通信，一般构建在tcp之上，tcp提供一个可靠的，面向连接的传输服务。 协议不安全的原因 数据没有加密 无法验证身份 数据容易篡改 对称加密算法 块密码算法 - 每次对固定长度的数据库进行加密，可能要经过一次或者多次运算，最终得到密文。 流密码算法 - 明文和同样长度的序列进行XOR运算得到密文。密文与加密使用的序列再进行XOR运算得到明文。 非对称加密算法(公开密钥算法) 和对称加密算法功能不一样，用来加密和解密，密钥协商，数字签名。 密钥是一对（公钥和私钥） 运行速度很慢，公开加密算法尤其是RSA算法运行非常缓慢，一般情况下，需要加密得明文数据很大，如果用非对称加密算法，运行性能会惨不忍睹。 消息验证码 MAC(message authentication code) hash算法能够实现完整性校验，但是不能避免消息被篡改，为避免消息被篡改，需要用到消息验证码。 发送方和接收方维护一个密钥，然后生成验证消息码，可以和原始消息一起传递，原始消息也可以加密，接收方比较mac值。 HTTP+LTS/SSL协议组合在一起就是https，就是说https拥有http得所有特征，并且http消息由TLS/SSL协议进行安全保护。 客户端发送https请求就是连接服务器443端口，讲所有得http数据传递给TLS/SSL协议，最终由TLS/SSL协议传递给TCP传输层。 TLS/SSL协议三大核心步骤：认证，密钥协商，数据加密。 在HTTPS协议中，客户端和服务端双方是互相不认识得，客户端可以是世界上任何一台机器得浏览器，必须采用动态密钥分配方式，这个时候密钥协商算法就出场了。 在公开密钥算法中，所有的网络通信都会存在中间人攻击，在https中必须引入PKI技术解决身份验证的问题，PKI的核心技术就是证书。PKI技术能够确保客户端接收到的服务器公钥确实是期待服务端的公钥。]]></content>
      <categories>
        <category>Http</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件流]]></title>
    <url>%2F2019%2F08%2F06%2FDotNet%2F%E6%96%87%E4%BB%B6%E6%B5%81%2F</url>
    <content type="text"><![CDATA[文件 文件是存储在具有特定名称和目录路径的磁盘中的数据的集合。当文件打开以进行读取或写入时，它将成为流。 流基本上是通过通信路径的字节序列。有两个主要流：输入流和输出流。输入流用于从文件读取数据(读取操作)，输出流用于写入文件(写入操作)。 FileStream12345678910111213// 写入FileStream f = new FileStream("e:\\filestream-demo.txt", FileMode.OpenOrCreate);//creating file stream f.WriteByte(65);//writing byte into stream f.Close();//closing stream// 读取FileStream f = new FileStream("e:\\filestream-demo.txt", FileMode.OpenOrCreate);int i = 0; while ((i = f.ReadByte()) != -1) &#123; Console.Write((char)i); &#125; f.Close(); StreamReader1234567891011121314151617181920// 一行一行读取FileStream f = new FileStream("e:\\myoutput.txt", FileMode.OpenOrCreate);StreamReader s = new StreamReader(f);string line = s.ReadLine();Console.WriteLine(line);string line2 = s.ReadLine();Console.WriteLine(line2);s.Close();f.Close();// 读取所有FileStream f = new FileStream("e:\\myoutput.txt", FileMode.OpenOrCreate);StreamReader s = new StreamReader(f);string line = "";while ((line = s.ReadLine()) != null)&#123; Console.WriteLine(line);&#125;s.Close();f.Close(); 大文本拷贝123456789101112131415161718192021222324252627282930313233private static void CopyFile(string source, string target) &#123; //创建一个读文件的流 using (FileStream fsread = new FileStream(source, FileMode.Open)) &#123; //创建一个写文件流 using (FileStream fswrite = new FileStream(target, FileMode.Create)) &#123; //创建一个读取文件、写入文件的一个缓冲区 //设置缓冲区大小，每次读取内容放到缓冲区中 byte[] buffer = new byte[1024 * 1024 * 10];//10MB long len = fsread.Length; //开始读取 while (true) &#123; //r 表示本次读到的字节数 int r = fsread.Read(buffer, 0, buffer.Length); if (r &lt;= 0) //已经到了文件末尾 &#123; break; &#125; else //读到了内容 &#123; fswrite.Write(buffer, 0, r); long allong = fswrite.Length; //已经拷贝的长度 double proc = (double)allong / len; Console.WriteLine("复制进度：" + proc + "%"); &#125; &#125; &#125; &#125; &#125; https://www.yiibai.com/csharp/c-sharp-stringreader.html]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>DotNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Css属性]]></title>
    <url>%2F2019%2F08%2F06%2F%E5%89%8D%E7%AB%AF%2FCss%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[行内元素和块级元素 行内元素会在一条直线上排列（默认宽度只与内容有关），都是同一行的，水平方向排列。 块级元素各占据一行（默认宽度是它本身父容器的100%（和父元素的宽度一致），与内容无关），垂直方向排列。块级元素从新行开始，结束接着一个断行。 块级元素可以包含行内元素和块级元素。行内元素不能包含块级元素，只能包含文本或者其它行内元素。 行内元素与块级元素属性的不同，主要是盒模型属性上：行内元素设置width无效，height无效(可以设置line-height)，margin上下无效，padding上下无效 行内元素和块级元素转换 display:block; (字面意思表现形式设为块级元素) display:inline; (字面意思表现形式设为行内元素) inline-block 的元素（如input、img)既具有 block 元素可以设置宽高的特性，同时又具有 inline 元素默认不换行的特性。当然不仅仅是这些特性，比如 inline-block 元素也可以设置 vertical-align（因为这个垂直对齐属性只对设置了inline-block的元素有效） 属性。HTML 中的换行符、空格符、制表符等合并为空白符，字体大小不为 0 的情况下，空白符自然占据一定的宽度，使用inline-block 会产生元素间的空隙。 行内元素和块级元素区别]]></content>
      <tags>
        <tag>Css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Consul]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%2FConsul%2F</url>
    <content type="text"><![CDATA[Consul Consul包含多个组件,但是作为一个整体,为你的基础设施提供服务发现和服务配置的工具。 服务发现：Consul的客户端可提供一个服务，比如api或者mysql，另外一些客户端可使用Consul去发现一个指定的服务提供者，通过DNS或者Http应用程序很容易找到他依赖的服务。 健康检查：Consul客户端可提供任意数量的健康检查，指定一个服务（比如一个api是否返回了200）或者使用本地节点（比如内存是否大于90%），这个信息可由opreator用来监视集群的健康，被服务发现组件用来避免将流量发送到不健康的主机。 Key/Value存储：应用程序可根据自己需要使用的Consul的层级的Key/Value存储，比如动态配置，功能标记，协调，领袖选举等。 多数据中心：Consul支持开箱即用的多数据中心，这意味着用户不需要担心建立额外的抽象层让业务扩展到多个区域，Consul面对DevOps和应用开发者友好，是他适合现代弹性的基础设置。 Consul使用场景 Docker 实例的注册与配置共享。 Coreos 实例的注册与配置共享。 SaaS 应用的配置共享、服务发现和健康检查。 vitess 集群。 与 confd 服务集成，动态生成 nginx 和 haproxy 配置文件。 Consul优势 市面现在有很多类似的软件比如：zookeeper 、Etcd、doozerd、eureka，Consul 相比这些软件有什么优势呢？ 使用 Raft 算法来保证一致性, 比复杂的 Paxos 算法更直接. 相比较而言, zookeeper 采用的是 Paxos, 而 etcd 使用的则是 Raft。 支持 多数据中心，内外网的服务采用不同的端口进行监听。 多数据中心集群可以避免单数据中心的单点故障，而其部署则需要考虑网络延迟，分片等情况等. zookeeper 和 etcd 均不提供多数据中心功能的支持。 支持 健康检查。 etcd 不提供此功能。 支持 HTTP、DNS 和 GPRS 协议接口。 zookeeper 的集成较为复杂，etcd 只支持 http 协议。 官方提供 WEB管理界面，etcd 无此功能。 Glossary Client：表示 Consul 客户端模式，是 Consul 节点的一种模式，所有注册到 Client 节点的服务会被转发到 Server 。本身无状态不持久化如何数据。Client 通过 HTTP、DNS、GRPC 接口请求转发给局域网内的服务端集群。 Server：表示 Consul 的服务端模式， Server 功能和 Client 都一样，不同的是 Server 持久化数据到本地。在局域网内与本地 Client 通讯，通过广域网与其他数据中心通讯。每个数据中心的 Server 数量推荐为 3 个或是 5 个。 Server-Leader ：表示这个 Server 是它们的老大，它和其它 Server 不一样的一点是，它需要负责同步注册的信息给其它的 Server 节点，同时也要负责各个节点的健康监测。如果 Leader 宕机了，通数据中心的所有 Server 内部会使用 Raft 算法来在其中选取一个 Leader 出来。 Agent ：Agent 是 Consul 的核心进程，Agent 的工作是维护成员关系信息、注册服务、健康检查、响应查询等等。Consul 集群的每一个节点都必须运行 agent 进程。 Consul的工作原理 使用微服务架构。传统的单体架构不够灵活不能很好的适应变化，从而向微服务架构进行转换，而伴随着大量服务的出现，管理运维十分不便，于是开始搞一些自动化的策略，服务发现应运而生。但是引入服务发现就可能引入一些技术栈，增加系统总体的复杂度。 在服务器Server1、Server2、Server3上分别部署了Consul Server，假设他们选举了Server2上的Consul Server节点为Leader. 在服务器Server4和Server5上通过Consul Client分别注册Service A、B、C。服务注册到Consul可以通过HTTP API（8500端口）的方式，也可以通过Consul配置文件的方式。Consul Client可以认为是无状态的，它将注册信息通过RPC转发到Consul Server，服务信息保存在Server的各个节点中，并且通过Raft实现了强一致性。 在服务器Server6中Program D需要访问Service B，这时候Program D首先访问本机Consul Client提供的HTTP API，本机Client会将请求转发到Consul Server，Consul Server查询到Service B当前的信息返回，最终Program D拿到了Service B的所有部署的IP和端口，然后就可以选择Service B的其中一个部署并向其发起请求了。如果服务发现采用的是DNS方式，则Program D中直接使用Service B的服务发现域名，域名解析请求首先到达本机DNS代理，然后转发到本机Consul Client，本机Client会将请求转发到Consul Server，Consul Server查询到Service B当前的信息返回，最终Program D拿到了Service B的某个部署的IP和端口。 http://blog.didispace.com/consul-service-discovery-exp 参数说明 advertise：通知展现地址用来改变我们给集群中的其他节点展现的地址，一般情况下-bind地址就是展现地址。 bootstrap： 用来控制一个server是否在bootstrap模式，在一个datacenter中只能有一个server处于bootstrap模式，当一个server处于bootstrap模式时，可以自己选举为raft leader。 bootstrap-expect：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用。 bind：该地址用来在集群内部的通讯IP地址，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0。 client：consul绑定在哪个client地址上，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1。 config-file：明确的指定要加载哪个配置文件。 config-dir：配置文件目录，里面所有以.json结尾的文件都会被加载。 data-dir：提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在。 dc:该标记控制agent允许的datacenter的名称，默认是dc1。 encrypt： 指定secret key，使consul在通讯时进行加密，key可以通过consul keygen生成，同一个集群中的节点必须使用相同的key。 join：加入一个已经启动的agent的ip地址，可以多次指定多个agent的地址。如果consul不能加入任何指定的地址中，则agent会启动失败，默认agent启动时不会加入任何节点。 retry-interval：两次join之间的时间间隔，默认是30s。 retry-max：尝试重复join的次数，默认是0，也就是无限次尝试。 log-level：consul agent启动后显示的日志信息级别。默认是info，可选：trace、debug、info、warn、err。 node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名。 protocol：consul使用的协议版本。 rejoin：使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。 server：定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个。 syslog：开启系统日志功能，只在linux/osx上生效。 pid-file：提供一个路径来存放pid文件，可以使用该文件进行SIGINT/SIGHUP(关闭/更新)agent。 1234567891011121314151617# 启动Consul和web管理docker run -d -p 8001:8500 --name consulserver-01 consul agent -server -bootstrap -ui -node=Node-01 -client='0.0.0.0' -data-dir ~/consul/data -config-dir ~/consul/configdocker run -d --name consulserver-02 consul agent -server -bootstrap -ui -node=Node-02 -client='0.0.0.0' -data-dir /var/vdb1/wangjun/consul/data -config-dir /var/vdb1/wangjun/consul/config -join='172.17.0.2'docker run -d --name consulserver-03 consul agent -server -bootstrap -ui -node=Node-03 -client='0.0.0.0' -data-dir /var/vdb1/wangjun/consul/data -config-dir /var/vdb1/wangjun/consul/config -join='172.17.0.2'docker run -d --name consulclient-01 consul agent -client -bootstrap -ui -node=Node-client-01 -client='0.0.0.0' -data-dir /var/vdb1/wangjun/consul/data -config-dir /var/vdb1/wangjun/consul/config -join='172.17.0.2'# 查看consul信息docker exec consul_server_1 consul members#Node Address Status Type Build Protocol DC Segment#1 172.17.0.2:8301 alive server 1.5.2 2 dc1 &lt;all&gt;#通过命令获取到引导 Consul 的 Ip 地址 172.17.0.2 #加入到集群， 命名为 -node=2 、-node=3 docker run -d --name=consul_server_2 consul agent -server -bootstrap -ui -node=2 -client='0.0.0.0' -join='172.17.0.2' docker run -d --name=consul_server_3 consul agent -server -bootstrap -ui -node=3 -client='0.0.0.0' -join='172.17.0.2' # 添加Client docker run -d --name=consul_server_4 consul agent -client -node=4 -join='172.17.0.2' -client='0.0.0.0' # Client需要集群继续添加node5，6就好]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Async-Await]]></title>
    <url>%2F2019%2F07%2F21%2FDotNet%2FAsync-Await%2F</url>
    <content type="text"><![CDATA[Task对象的前世今生 Task对象是.Net Framework 4.0之后出现的异步编程的一个重要对象。在一定程度上来说，Task对象可以理解Thread对象的一个升级产品。 示例 12345678910111213141516171819class Program&#123; static void Main(string[] args) &#123; Console.WriteLine("执行方法之前的时间：" + DateTime.Now.ToString("yyyy-MM-dd hh:MM:sss")); var result = Task.Run(() =&gt;&#123;return GetResult();&#125;); Console.WriteLine("主线程Id:" + Thread.CurrentThread.ManagedThreadId); Console.WriteLine(result.Result); Console.WriteLine("执行方法之后的时间：" + DateTime.Now.ToString("yyyy-MM-dd hh:MM:sss")); Console.ReadKey(); &#125; public static string GetResult() &#123; Thread.Sleep(2000); Console.WriteLine("GetResult的线程Id:" + Thread.CurrentThread.ManagedThreadId); return "WangJunZzz"; &#125;&#125; 结果 123456789#执行方法之前的时间：2019-07-21 01:07:42#WangJunZzz#执行方法之后的时间：2019-07-21 01:07:44#PS E:\Code\async\async-await&gt; dotnet run#执行方法之前的时间：2019-07-21 01:07:52#主线程Id:1#GetResult的线程Id:3#WangJunZzz#执行方法之后的时间：2019-07-21 01:07:54 从结果分析得知，var result = Task.Run(() =&gt;{return GetResult();});这一句后，主线程并没有阻塞取执行GetResult()方法，而是开启一个线程取执行GetResult()方法。知道执行result.Result这一句的时候才会等待GetResult()方法执行完毕。由此可知，Task.Run(()=&gt;{}).Reslut是阻塞主线程的，主要因为主线程要得到返回值，必须等方法执行完毕。 线程不安全 示例 12345678910111213141516171819class Program&#123; private static bool isDone = false; static void Main(string[] args) &#123; new Thread(Done).Start(); new Thread(Done).Start(); Console.ReadKey(); &#125; static void Done() &#123; if (!isDone) &#123; Console.WriteLine("Done"); isDone = true; &#125; &#125;&#125; 结果 12#Done#Done 第一个线程还没有来得及把isDone设置成true，第二个线程就进来了，而这不是我们想要的结果，在多个线程下，结果不是我们的预期结果，这就是线程不安全。 锁 示例1234567891011121314151617181920212223class Program&#123; private static bool isDone = false; private static object mylock = new object(); static void Main(string[] args) &#123; new Thread(Done).Start(); new Thread(Done).Start(); Console.ReadKey(); &#125; static void Done() &#123; lock(mylock) &#123; if (!isDone) &#123; Console.WriteLine("Done"); isDone = true; &#125; &#125; &#125;&#125; 加上锁之后，被锁住的代码在同一个时间内只允许一个线程访问，其它的线程会被阻塞，只有等到这个锁被释放之后其它的线程才能执行被锁住的代码。 Async,Await 使用它们，方法的返回类型应为Task类型。为了使用await关键字，您必须在方法定义中使用async。如果你在方法定义中放入async，你应该在主体方法的某个地方至少有一处await关键字，如果你缺少他，你通常会收到Visual Studio的一个警告。 await 之后不会开启新的线程(await 从来不会开启新的线程)。 加上await关键字之后，后面的代码会被挂起等待，直到task执行完毕有返回值的时候才会继续向下执行，这一段时间主线程会处于挂起状态。 Task.Run(()=&gt;{}); 将一个任务添加到线程池里，排队执行。 async 标识一个方法为异步方法，可以与主线程并行执行，发挥CPU的多核优势。 await 在调用一个async方法前可以添加这个修饰符，它意思是等待当前异步方法执行完后，再执行下面的代码。 ConfigureAwait(true)，代码由同步执行进入异步执行时，当前线程上下文信息就会被捕获并保存至 SynchronizationContext中，供异步执行中使用，并且供异步执行完成之后的同步执行中使用。 Configurewait(flase)，不进行线程上下文信息的捕获，async方法中与await之后的代码执行时就无法获取await之前的线程的上下文信息，在ASP.NET中最直接的影响就是HttpConext.Current的值为null，但不会出现非空引用的错误。 async配合Task是为了简化异步调用，异步调用的目的恰恰就是为了释放线程资源。 在await的时候，线程就被释放了，等到异步操作完成才会回头来继续执行后面的代码。async的用途恰恰就在于避免阻塞，写的代码看起来像是同步的阻塞代码，但编译后不是，这才是async的精髓。(https://www.cnblogs.com/jesse2013/p/async-and-await.html 评论)。 在.NetCore中我们不用继续关心异步同步混用情况下，是否哪里没有设置ConfigureAwait(false) 会导致的死锁问题，因为在.netcore中的async/await 可能在任何线程上执行，并且可能并行运行！。]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EventBus]]></title>
    <url>%2F2019%2F07%2F09%2FDotNet%2FEventBus%2F</url>
    <content type="text"><![CDATA[引言 事件总线这个概念对你来说可能很陌生，但提到观察者（发布-订阅）模式，你也许就很熟悉。事件总线是对发布-订阅模式的一种实现。它是一种集中式事件处理机制，允许不同的组件之间进行彼此通信而又不需要相互依赖，达到一种解耦的目的。 本质：事件是由事件源和事件处理组成。 发布订阅模式：定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知并被自动更新。 ——发布订阅模式。 基本思路 在事件总线内部维护着一个事件与事件处理程序相映射的字典。 利用反射，事件总线会将实现了IEventHandler的处理程序与相应事件关联到一起，相当于实现了事件处理程序对事件的订阅。 当发布事件时，事件总线会从字典中找出相应的事件处理程序，然后利用反射去调用事件处理程序中的方法。 基于内存事件总线实现 定义一个事件接口 123public interface IEvent&#123;&#125; 定义一个事件处理接口 1234public interface IEventHandler : IEvent&#123; Task Handle(IEvent e);&#125; 定义一个发布接口 1234public interface IEventPublisher&#123; Task Publish&lt;TEvent&gt;(TEvent e) where TEvent : IEvent;&#125; 定义一个发布接口 1234public interface IEventSubscriber &#123; Task Subscribe&lt;TEvent, EH&gt;() where TEvent : IEvent where EH : class, IEventHandler, new();&#125; 创建一个类用来存事件 1234public static class MemoryMq&#123; public static ConcurrentDictionary&lt;string, IEvent&gt; eventQueueDict &#123; get; set; &#125;&#125; 实现发布类 12345678910111213public class InMemoryEventPublisher : IEventPublisher&#123; public Task Publish&lt;TEvent&gt;(TEvent e) where TEvent : IEvent &#123; if (e == null) return Task.CompletedTask; if (MemoryMq.eventQueueDict == null) &#123; MemoryMq.eventQueueDict = new ConcurrentDictionary&lt;string, IEvent&gt;(); &#125; MemoryMq.eventQueueDict.GetOrAdd(Guid.NewGuid().ToString(), e); return Task.CompletedTask; &#125;&#125; 实现订阅类 1234567891011121314151617181920212223public class InMemoryEventSubscriber : IEventSubscriber&#123; public Task Subscribe&lt;TEvent, EH&gt;() where TEvent : IEvent where EH : class, IEventHandler, new() &#123; EH state = new EH(); Task.Run(() =&gt; &#123; while (true) &#123; if (MemoryMq.eventQueueDict != null) &#123; foreach (var item in MemoryMq.eventQueueDict) &#123; state.Handle(item.Value as IEvent); IEvent o; MemoryMq.eventQueueDict.TryRemove(item.Key, out o); &#125; &#125; &#125; &#125;); return Task.CompletedTask; &#125; 实现逻辑处理 123456789101112131415161718public class EventHandler : IEventHandler&#123; public Task Handle(IEvent e) &#123; switch (e) &#123; case Order value: Console.WriteLine(value.Name); break; &#125; return Task.CompletedTask; &#125;&#125; public class Order : IEvent &#123; public string name &#123; get; set; &#125; &#125; 测试 1234567891011121314class Program&#123; static void Main(string[] args) &#123; var pub = new InMemoryEventPublisher(); var sub = new InMemoryEventSubscriber(); sub.Subscribe&lt;Order, EventHandler&gt;(); var order = new Order(); order.Name = "wangjunzzz"; pub.Publish(order); Console.WriteLine("Hello World!"); Console.ReadKey(); &#125;&#125; Code Source]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>事件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMq]]></title>
    <url>%2F2019%2F06%2F27%2FDotNet%2FRabbitMq%2F</url>
    <content type="text"><![CDATA[消息中间件 消息中间件是指利用高效可靠得消息传递机制进行与平台数据无关的数据交流，并基于数据通信来进行分布式系统集成。 RabbitMq整体上是一个生产者和消费者模型，主要负责接收，存储和转发消息。 RabbitMq就是AMQP(应用层高级消息队列协议)协议的Erlang的实现。 作用 解耦：独立修改或者扩展两边的处理过程，只要确保遵循相同的接口约束即可。 削峰：使用中间件能够使关键组件支撑突发访问压力，不会因为突发的超负荷请求而完全崩溃。 异步通信：很多时候不想立即处理消息，中间件允许把消息放到中间件中，但是不立即处理它，之后需要的时候在慢慢处理。 名词解释 生产者：投递消息的一方. 消费者: 接收消息的一方. Broker：消息中间件的服务节点. Queue: 队列，RabbitMq的内部对象. 交换器：生产者把消息发送到Exchange（交换器）,由交换器把消息路由到一个或者多个队列中,如果路由不到,或许会返回给生产者,或许会直接丢弃.RabbitMq有四种交换机类型:交换机类型 五种模式 简单模式：一个生产者，一个消费者. 简单模式特点，其实就是是生成者直接将消息发送给队列，消费者直接从队列取消息，中间没有其他的东西，并且1对1的。 生产者 123456789101112131415161718192021222324252627282930//创建mq的连接工厂var factory = new ConnectionFactory();factory.HostName = "119.29.225.20";factory.UserName = "userId";factory.Password = "pwd";//创建一个连接var connection = factory.CreateConnection();//创建一个频道var channel = connection.CreateModel();//创建一个队列// durable:持久化可以把交换器存盘，在服务器重启的时候不会丢失相关信息.// exclusive:如果申明为排它队列,该队列仅对首次申明它的连接可见,并且在连接断开的时候自动删除,// autoDelete:是否自动删除,自动删除的前提是：至少又一个消费者连接到这个队列,// 之后所有与这个队列连接的消费者都断开时,才会自动删除.channel.QueueDeclare(queue: "hello", durable: false, exclusive: false, autoDelete: false, arguments: null);for (int i = 0; i &lt; 50; i++)&#123; string message = "Hello World!"+i; var body = Encoding.UTF8.GetBytes(message) // 发送消息 channel.BasicPublish(exchange: "", routingKey: "hello", basicProperties: null, body: body); Console.WriteLine(" [x] Sent &#123;0&#125;", message);&#125; 消费者 1234567891011121314151617181920212223242526var factory = new ConnectionFactory();factory.HostName = "119.29.225.20";factory.UserName = "userId";factory.Password = "pwd";using (var connection = factory.CreateConnection())&#123; using (var channel = connection.CreateModel()) &#123; channel.QueueDeclare(queue: "hello", durable: false, exclusive: false, autoDelete: false, arguments: null); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =&gt; &#123; var body = ea.Body; var message = Encoding.UTF8.GetString(body); Console.WriteLine(" [x] Received &#123;0&#125;", message); &#125;; channel.BasicConsume(queue: "hello", autoAck: true, consumer: consumer); Console.ReadKey(); &#125;&#125; 工作模式：一个生产者,多个消费者. 消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2,同时监听同一个队列,消息被消费?C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患,高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize,与同步锁的性能不一样) 保证一条消息只能被一个消费者使用).一条消息只会被一个消费者接收；rabbit采用轮询的方式将消息是平均发送给消费者的；消费者在处理完某条消息后，才会收到下一条消息. 12]]></content>
      <categories>
        <category>DotNet</category>
      </categories>
      <tags>
        <tag>RabbitMq</tag>
      </tags>
  </entry>
</search>
